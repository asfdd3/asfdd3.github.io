[{"title":"内核socket套接字的创建","url":"/2025/05/21/%E5%86%85%E6%A0%B8socket%E5%88%9B%E5%BB%BA/","content":"内核socket创建用户程序执行syscall指令，系统会从用户态陷入内核态并根据传入的系统调用号（例如在x86架构下socket系统调用号为41）从系统调用表中找到对应的处理函数，socekt（）系统调用对应的处理函数如下所示：\nSYSCALL_DEFINE3(socket, int, family, int, type, int, protocol)&#123; return __sys_socket(family, type, protocol);&#125;\n\n上述宏SYSCALL_DEFINE3(socket, int, family, int, type, int, protocol)经过一系列展开后其实就是系统调用表中系统调用号41对应的处理函数\n上述__sys_socket函数定义如下：\n1.sock_create（）int __sys_socket(int family, int type, int protocol)&#123; struct socket *sock; int flags; //根据传入的参数创建socket sock = __sys_socket_create(family, type,       update_socket_protocol(family, type, protocol)); if (IS_ERR(sock))  return PTR_ERR(sock); //不关心低4bit sock的type flags = type &amp; ~SOCK_TYPE_MASK; if (SOCK_NONBLOCK != O_NONBLOCK &amp;&amp; (flags &amp; SOCK_NONBLOCK))  //清位之后置位  flags = (flags &amp; ~SOCK_NONBLOCK) | O_NONBLOCK; //将socket映射一个文件描述符号 return sock_map_fd(sock, flags &amp; (O_CLOEXEC | O_NONBLOCK));&#125;\n\n该函数主要做了两个事情，创建socekt和映射描述符fd。\n上面创建socket函数__sys_socket_create定义如下：\n2.__sys_socket_create（）static struct socket *__sys_socket_create(int family, int type, int protocol)&#123; struct socket *sock; int retval; /* Check the SOCK_* constants for consistency.  */ BUILD_BUG_ON(SOCK_CLOEXEC != O_CLOEXEC); BUILD_BUG_ON((SOCK_MAX | SOCK_TYPE_MASK) != SOCK_TYPE_MASK); BUILD_BUG_ON(SOCK_CLOEXEC &amp; SOCK_TYPE_MASK); BUILD_BUG_ON(SOCK_NONBLOCK &amp; SOCK_TYPE_MASK); //用户参数合法性检查，是否有非法标志位 if ((type &amp; ~SOCK_TYPE_MASK) &amp; ~(SOCK_CLOEXEC | SOCK_NONBLOCK))  return ERR_PTR(-EINVAL); type &amp;= SOCK_TYPE_MASK; //创建套接字 retval = sock_create(family, type, protocol, &amp;sock); if (retval &lt; 0)  return ERR_PTR(retval); return sock;&#125;\n\n上述sock_create为实际创建socket的函数，它包裹了__sock_create()如下所示：\nint sock_create(int family, int type, int protocol, struct socket **res)&#123; return __sock_create(current-&gt;nsproxy-&gt;net_ns, family, type, protocol, res, 0);&#125;\n\n可以看到__sock_create多带了一个参数current-&gt;nsproxy-&gt;net_ns  这个current是一个宏，用于获取当前进程的task_struct指针\ncurrent宏定义如下:\nstatic __always_inline struct task_struct *get_current(void)&#123; //这个pcpu_hot中有一个字段就是current_task也就是task_struct //this_cpu_read_stable()就是读取per_cpu变量的一个宏 return this_cpu_read_stable(pcpu_hot.current_task);//从per-cpu变量中获取当前的task_sturct结构&#125;\n\n上述current宏其实等同于指向一个task_struct的指针，而__sock_create(current-&gt;nsproxy-&gt;net_ns, family, type, protocol, res, 0);中参数current-&gt;nsproxy-&gt;net_ns就是指向一个具体的网络命名空间，为什么要传入这个网络命令空间作为参数？举个例子，如果进程属于某个容器的网络命名空间，创建的套接字必须关联到该容器的网络栈，而非宿主机的默认命名空间， 比如在创建docker进程的时候，就会设置sproxy-&gt;net_ns所属的网络命令空间。最终的目的一定是为了流量隔离。\n接下来看一下真正创建socket的函数__sock_create\n3.__sock_create()int __sock_create(struct net *net, int family, int type, int protocol,\t\t\t struct socket **res, int kern)&#123;\tint err;\tstruct socket *sock;\tconst struct net_proto_family *pf;\t//合法性检查\tif (family &lt; 0 || family &gt;= NPROTO)\t\treturn -EAFNOSUPPORT;\tif (type &lt; 0 || type &gt;= SOCK_MAX)\t\treturn -EINVAL;\t//过时的 PF_INET + SOCK_PACKET 参数组合转换为现代支持的 PF_PACKET 协议族\tif (family == PF_INET &amp;&amp; type == SOCK_PACKET) &#123;\t\tpr_info_once(&quot;%s uses obsolete (PF_INET,SOCK_PACKET)\\n&quot;,\t\t\t     current-&gt;comm);\t\tfamily = PF_PACKET;\t&#125;\t//安全相关的钩子\terr = security_socket_create(family, type, protocol, kern);\tif (err)\t\treturn err;\t//分配并初始化一个套接字对应的 inode 和socket 结构\tsock = sock_alloc();\tif (!sock) &#123;\t\tnet_warn_ratelimited(&quot;socket: no more sockets\\n&quot;);\t\treturn -ENFILE;\t//这里的type也是用户创建socket的type\tsock-&gt;type = type;\trcu_read_lock();\t//从sock_register数组中找到一个元素pf，这个pf中有一个create()回调函数，\t//这个回调函数就是family类型(比如AF_INET)需要的create函数。\tpf = rcu_dereference(net_families[family]);\terr = -EAFNOSUPPORT;\tif (!pf)\t\tgoto out_release;\t//增加引用计数？有些family可能是以模块方式加载的？？？\tif (!try_module_get(pf-&gt;owner))\t\tgoto out_release;\t/* Now protected by module ref count */\trcu_read_unlock();\t//如果用户指定的family类型是AF_INIT,那这个函数就是调用的inet_create()\terr = pf-&gt;create(net, sock, protocol, kern);\tif (err &lt; 0)\t\tgoto out_module_put;\tif (!try_module_get(sock-&gt;ops-&gt;owner))\t\tgoto out_module_busy;\t//减引用计数\tmodule_put(pf-&gt;owner);\t//安全模块相关\terr = security_socket_post_create(sock, family, type, protocol, kern);\tif (err)\t\tgoto out_sock_release;\t*res = sock;\treturn 0;out_module_busy:\terr = -EAFNOSUPPORT;out_module_put:\tsock-&gt;ops = NULL;\tmodule_put(pf-&gt;owner);out_sock_release:\tsock_release(sock);\treturn err;out_release:\trcu_read_unlock();\tgoto out_sock_release;&#125;EXPORT_SYMBOL(__sock_create);\n\n\n上述代码中通过调用sock_alloc()分配了inode和socket结构体，并对inode结构体进行初始化，比如设置唯一的inode编号等，具体代码如下：\nstruct socket *sock_alloc(void)&#123;\tstruct inode *inode;\tstruct socket *sock;\t//调用socket文件系统的超级块的ops申请一个inode，注意：socket结构体也是在这里分配的\tinode = new_inode_pseudo(sock_mnt-&gt;mnt_sb);\tif (!inode)\t\treturn NULL;\t//通过container_of拿到socket结构体 \tsock = SOCKET_I(inode);\tinode-&gt;i_ino = get_next_ino();//分配唯一的inode编号\tinode-&gt;i_mode = S_IFSOCK | S_IRWXUGO; //文件类型\tinode-&gt;i_uid = current_fsuid();\tinode-&gt;i_gid = current_fsgid();\tinode-&gt;i_op = &amp;sockfs_inode_ops;//绑定ops\treturn sock;&#125;\n\n上述代码通过调用new_inode_pseudo()创建了inode和socket，socket的获取通过宏SOCKET_I（container_of）返回socket其中sock_mnt是一个vfsmount(可以理解为一个挂载点)结构mnt_sb为一个超级块，在sock_init()中被挂载，sock_init()在start_kernel中会最终被调用到。\npf = rcu_dereference(net_families[family]); 这一行作用是根据用户传入的不同的协议族（比如AF_INET）来选择具体的回调函数，然后会调用pf-&gt;create(net, sock, protocol, kern); 这个-&gt;create() 就取决于family的类型。对于AF_INET类型的family，就是调用inet_create()，注册的过程由sock_register()实现，该函数就是将不同的family类型，注册到一个数组中(这个数组叫net_families)。对应的函数如下：\nint sock_register(const struct net_proto_family *ops)&#123;\tint err;\tif (ops-&gt;family &gt;= NPROTO) &#123;\t\tpr_crit(&quot;protocol %d &gt;= NPROTO(%d)\\n&quot;, ops-&gt;family, NPROTO);\t\treturn -ENOBUFS;\t&#125;\tspin_lock(&amp;net_family_lock);\tif (rcu_dereference_protected(net_families[ops-&gt;family],\t\t\t\t      lockdep_is_held(&amp;net_family_lock)))\t\terr = -EEXIST;\telse &#123;\t\t//这里注册了不同family类型到net_families数组中！\t\trcu_assign_pointer(net_families[ops-&gt;family], ops);\t\terr = 0;\t&#125;\tspin_unlock(&amp;net_family_lock);\tpr_info(&quot;NET: Registered %s protocol family\\n&quot;, pf_family_names[ops-&gt;family]);\treturn err;&#125;\n\n对于AF_INET(ipv4)协议族，上述注册的函数为inet_create()，在inet_init()中被调用，同样inet_init()也是最终被start_kernel()调用到。\n也就是说err = pf-&gt;create(net, sock, protocol, kern);会根据协议族的类型调用不同的create函数，同时传入用户制定的类型(TYPE)和协议做为参数，下面默认使用ipv4协议族进行举例，待分析函数就是inet_create()函数实现如下所示：\n也就是说err = pf-&gt;create(net, sock, protocol, kern);会根据协议族的类型调用不同的create函数，同时传入用户制定的类型(TYPE)和协议做为参数，下面使用ipv4协议族进行举例，对应的函数就是inet_create()，该函数其实主要处理了三个逻辑：\n\n根据用户制定协议从inetsw找到socket和sock对应的ops\n创建sock结构，并进行一系列的初始化（例如绑定sock的ops，这里不同的协议对应不同的ops）\n调用sock的init函数，完成对具体协议的初始化inet_create函数定义如下：\n\nstatic int inet_create(struct net *net, struct socket *sock, int protocol,\t\t       int kern)&#123;\tstruct sock *sk;\tstruct inet_protosw *answer;\tstruct inet_sock *inet;\tstruct proto *answer_prot;\tunsigned char answer_flags;\tint try_loading_module = 0;\tint err;\t\t//参数合法性检查\tif (protocol &lt; 0 || protocol &gt;= IPPROTO_MAX)\t\treturn -EINVAL;\t//初始化socket的状态\tsock-&gt;state = SS_UNCONNECTED;\t/* Look for the requested type/protocol pair. */lookup_protocol:\terr = -ESOCKTNOSUPPORT;\trcu_read_lock();\t//遍历inetsw[sock-&gt;type]这个元素的链表，找到protocol相同的元素，\tlist_for_each_entry_rcu(answer, &amp;inetsw[sock-&gt;type], list) &#123;\t\terr = 0;\t\t/* Check the non-wild match. */\t\t//精确匹配，用户指定的protocol和链表中的某个元素相同。\t\tif (protocol == answer-&gt;protocol) &#123;\t\t\tif (protocol != IPPROTO_IP)\t\t\t\tbreak;\t\t&#125; else &#123;\t\t\t/* Check for the two wild cases. */\t\t\t//如果用户指定的proto是0那就走这个分支，\t\t\t//比如type是SOCK_STREAM，proto=0 那answer关联的就是TCP\t\t\tif (IPPROTO_IP == protocol) &#123;\t\t\t\tprotocol = answer-&gt;protocol;\t\t\t\tbreak;\t\t\t&#125;\t\t\tif (IPPROTO_IP == answer-&gt;protocol)\t\t\t\tbreak;\t\t&#125;\t\terr = -EPROTONOSUPPORT;\t&#125;\t//错误的处理\tif (unlikely(err)) &#123;\t\tif (try_loading_module &lt; 2) &#123;\t\t\trcu_read_unlock();\t\t\t/*\t\t\t * Be more specific, e.g. net-pf-2-proto-132-type-1\t\t\t * (net-pf-PF_INET-proto-IPPROTO_SCTP-type-SOCK_STREAM)\t\t\t */\t\t\tif (++try_loading_module == 1)\t\t\t\trequest_module(&quot;net-pf-%d-proto-%d-type-%d&quot;,\t\t\t\t\t       PF_INET, protocol, sock-&gt;type);\t\t\t/*\t\t\t * Fall back to generic, e.g. net-pf-2-proto-132\t\t\t * (net-pf-PF_INET-proto-IPPROTO_SCTP)\t\t\t */\t\t\telse\t\t\t\trequest_module(&quot;net-pf-%d-proto-%d&quot;,\t\t\t\t\t       PF_INET, protocol);\t\t\tgoto lookup_protocol;\t\t&#125; else\t\t\tgoto out_rcu_unlock;\t&#125;\terr = -EPERM;\t//用户有权限才能创建raw socket套接字\tif (sock-&gt;type == SOCK_RAW &amp;&amp; !kern &amp;&amp;\t    !ns_capable(net-&gt;user_ns, CAP_NET_RAW))\t\tgoto out_rcu_unlock;\t//将上述找到的answer-&gt;ops赋值给socket的ops\tsock-&gt;ops = answer-&gt;ops;\t//将上述找到的answer-&gt;ops赋值给answer_prot，下面创建sock结构的时候会用到\tanswer_prot = answer-&gt;prot;\tanswer_flags = answer-&gt;flags;\trcu_read_unlock();\tWARN_ON(!answer_prot-&gt;slab);\terr = -ENOMEM;\t//注意： 这里申请一个sock结构，这个sock结构可以理解为传输层协议和socket之间的一个中间层\t//对上提供socket层的结构，\t//对下与具体的协议相关\t//kern 标识这个套接字是否是内核创建的\tsk = sk_alloc(net, PF_INET, GFP_KERNEL, answer_prot, kern);\tif (!sk)\t\tgoto out;\terr = 0;\t//标识端口是否可以重用 这里raw 和icmp是设置了INET_PROTOSW_REUSE 这个标志位。\tif (INET_PROTOSW_REUSE &amp; answer_flags)\t\tsk-&gt;sk_reuse = SK_CAN_REUSE;\tinet = inet_sk(sk);\t//是否是一个面向连接套接字，对于TCP是有这个标志位的\tinet_assign_bit(IS_ICSK, sk, INET_PROTOSW_ICSK &amp; answer_flags);\tinet_clear_bit(NODEFRAG, sk);\t//如果是rawsocket就指定了端口号？\tif (SOCK_RAW == sock-&gt;type) &#123;\t\tinet-&gt;inet_num = protocol;\t\tif (IPPROTO_RAW == protocol)\t\t\tinet_set_bit(HDRINCL, sk);\t&#125;\t//根据系统参数决定是否开启mtu探测\tif (READ_ONCE(net-&gt;ipv4.sysctl_ip_no_pmtu_disc))\t\tinet-&gt;pmtudisc = IP_PMTUDISC_DONT;\telse\t\tinet-&gt;pmtudisc = IP_PMTUDISC_WANT;\t\t//设置ip_id字段\tatomic_set(&amp;inet-&gt;inet_id, 0);\t//这里初始化了上面申请的sock结构体的各个字段\tsock_init_data(sock, sk);\tsk-&gt;sk_destruct\t   = inet_sock_destruct;\t//这里记录了用户指定的协议\tsk-&gt;sk_protocol\t   = protocol;\tsk-&gt;sk_backlog_rcv = sk-&gt;sk_prot-&gt;backlog_rcv;\tsk-&gt;sk_txrehash = READ_ONCE(net-&gt;core.sysctl_txrehash);\t//初始化inet_sock的一些字段 单播/多播ttl，tos，管理多播的mc_list\tinet-&gt;uc_ttl\t= -1;   \tinet_set_bit(MC_LOOP, sk);\tinet-&gt;mc_ttl\t= 1;\tinet_set_bit(MC_ALL, sk);\tinet-&gt;mc_index\t= 0;\tinet-&gt;mc_list\t= NULL;\tinet-&gt;rcv_tos\t= 0;\t//tcp或者udp 应该不会走这个逻辑，因为还没有调用bind，inet_num此时应该为0\tif (inet-&gt;inet_num) &#123;\t\tinet-&gt;inet_sport = htons(inet-&gt;inet_num);\t\t/* Add to protocol hash chains. */\t\terr = sk-&gt;sk_prot-&gt;hash(sk);\t\tif (err) &#123;\t\t\tsk_common_release(sk);\t\t\tgoto out;\t\t&#125;\t&#125;\t//这里是特定协议的初始化逻辑\tif (sk-&gt;sk_prot-&gt;init) &#123;\t\terr = sk-&gt;sk_prot-&gt;init(sk);\t\tif (err) &#123;\t\t\tsk_common_release(sk);\t\t\tgoto out;\t\t&#125;\t&#125;\tif (!kern) &#123;\t\terr = BPF_CGROUP_RUN_PROG_INET_SOCK(sk);\t\tif (err) &#123;\t\t\tsk_common_release(sk);\t\t\tgoto out;\t\t&#125;\t&#125;out:\treturn err;out_rcu_unlock:\trcu_read_unlock();\tgoto out;&#125;\n\n上述代码首先根据用户指定的type和protocol类型从inewsw[]中找到匹配的socket和sock的ops，注意这里inewsw[]是一个数组，数组中的每个元素又是一个链表，其实可以理解成一个hash表，hash表的key是type，而protocol是用来寻找某个桶中的的具体的一个元素。上述的inet_sw数组中的元素是由inetsw_array[]中填充进来的，填充的过程在inet_init()函数中实现。inetsw_array[]数组的定义和填充inetsw[]的代码如下：\n//这个数组的作用就是把数组中的元素注册到inet_sw[]中static struct inet_protosw inetsw_array[] =&#123;\t&#123;\t\t.type =       SOCK_STREAM,\t\t.protocol =   IPPROTO_TCP,\t\t.prot =       &amp;tcp_prot,\t\t.ops =        &amp;inet_stream_ops,\t\t.flags =      INET_PROTOSW_PERMANENT |\t\t\t      INET_PROTOSW_ICSK,\t&#125;,\t&#123;\t\t.type =       SOCK_DGRAM,\t\t.protocol =   IPPROTO_UDP,\t\t.prot =       &amp;udp_prot,\t\t.ops =        &amp;inet_dgram_ops,\t\t.flags =      INET_PROTOSW_PERMANENT,       &#125;,       &#123;\t\t.type =       SOCK_DGRAM,\t\t.protocol =   IPPROTO_ICMP,\t\t.prot =       &amp;ping_prot,\t\t.ops =        &amp;inet_sockraw_ops,\t\t.flags =      INET_PROTOSW_REUSE,       &#125;,       &#123;\t       .type =       SOCK_RAW,\t       .protocol =   IPPROTO_IP,\t/* wild card */\t       .prot =       &amp;raw_prot,\t       .ops =        &amp;inet_sockraw_ops,\t       .flags =      INET_PROTOSW_REUSE,       &#125;&#125;;\n\n上述代码为inetsw_array[]数组，其中prot为socket的ops，用户态不同的系统调用会调用到socket的不同ops上。prot则为具体协议的ops。也就是说ops是socket关联的回调函数，prot为sock关联的回调函数，两者其实是密切相关的，可以理解为ops是用户与内核的一个桥梁或者中间层，而prot则是具体的实现。\n注册inetsw_array到inet_sw[]数组中的代码在inet_init()中，代码如下：\n//遍历inetsw_array数组中的元素后调用inet_register_protosw函数将元素插入到inetsw[]中\tfor (q = inetsw_array; q &lt; &amp;inetsw_array[INETSW_ARRAY_LEN]; ++q)\t\tinet_register_protosw(q);void inet_register_protosw(struct inet_protosw *p)&#123;\tstruct list_head *lh;\tstruct inet_protosw *answer;\tint protocol = p-&gt;protocol;\tstruct list_head *last_perm;\tspin_lock_bh(&amp;inetsw_lock);\t//合法性检查\tif (p-&gt;type &gt;= SOCK_MAX)\t\tgoto out_illegal;\t//last_perm保存的是一个socket-&gt;type中最后一个永久协议的位置\tlast_perm = &amp;inetsw[p-&gt;type];\tlist_for_each(lh, &amp;inetsw[p-&gt;type]) &#123;\t\tanswer = list_entry(lh, struct inet_protosw, list);\t\t/* Check only the non-wild match. */\t\t//不是永久协议的情况（TCP/UDP为永久协议）\t\tif ((INET_PROTOSW_PERMANENT &amp; answer-&gt;flags) == 0)\t\t\tbreak;\t\t//和永久协议的protocol一样\t\tif (protocol == answer-&gt;protocol)\t\t\tgoto out_permanent;\t\t//走到这里给永久协议赋值\t\tlast_perm = lh;\t&#125;\t//将新的协议注册到协议之后。\tlist_add_rcu(&amp;p-&gt;list, last_perm);out:\tspin_unlock_bh(&amp;inetsw_lock);\treturn;out_permanent:\tpr_err(&quot;Attempt to override permanent protocol %d\\n&quot;, protocol);\tgoto out;out_illegal:\tpr_err(&quot;Ignoring attempt to register invalid socket type %d\\n&quot;,\t       p-&gt;type);\tgoto out;&#125;\n","categories":["网络协议栈源码学习"],"tags":["socket"]},{"title":"VFS虚拟文件系统","url":"/2025/05/19/VFS%E8%99%9A%E6%8B%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/","content":"VFS(虚拟文件系统)1.什么是VFSLinux 需要支持多种不同的文件系统（因为不同的文件系统有不同的特点），同时还要为用户提供一组统一的接口，因此要实现这个目的，就要将对各种不同文件系统和管理纳入到一个统一的框架中，也就是同一组系统调用，对各种不同的文件系统进行操作，这就是存在VFS的目的。\n这样，就可以对用户程序隐去各种不同文件系统的细节，为用户程序提供一个统一的、抽象的、虚拟的文件系统，这就是所谓“虚拟文件系统” - VFS（Virtual Filesystem Switch）。这个抽象层由一组标准的、抽象的文件操作构成，以系统调用的形式提供于用户程序，如read（）、write（）、lseek（）等等。这样，用户程序就可以 把所有的文件都看作一致的、抽象的“VFS文件”，通过这些系统调用对文件进行操作，而无需关心具体的文件属于什么文件系统以及具体文件系统的设计和实现,也就是说VFS是一个内核软件层，使应用程序与具体的文件系统解耦。\n举一个例子：在编写应用程序时，会经常使用到write（）系统调用，也就是向一个文件中写入数据。函数的原型为 ssize_t write(int fd, const void *buf, size_t count); 用户程序调用write（f, &amp;buf, len）的含义为向文件描述符为f的文件中，写入len个字节数据，。下图为write（）将数据写入到设备上的宏观流程。我们看到首先通过虚拟文件系统VFS，然后根据不同文件系统的write（）方法将数据写入物理设备上，宏观的调用流程如下图所示：\n\n2.VFS 整体架构虚拟文件系统作为内核中的一个抽象层，起到一个中间层的作用，对上(应用程序)提供统一接口，应用程序只需使用标准的文件操作（如 open、read、write1），无需关心底层是哪种文件系统（EXT4、NTFS、FAT等），对下为各种具体的文件系统（如 ext4、XFS 等）提供了统一的接口（其实就是实现不同文件系统的ops集合），VFS在内核中的整体架构如下所示。\n\n\n\n上述图片为VFS整体架构图，图片中各个组件作用大概如下：\n\nAPP：用户程序通过系统调用读写文件\nPage Cache：缓存文件的数据内容，例如次读取文件时从磁盘加载到页缓存，后续直接读缓存，避免磁盘I&#x2F;O。\nDirectory cache：缓存文件路径到Dentry的映射，减少频繁解析路径的开销。\nInode缓存：缓存文件的元数据（权限、大小、数据块位置等）\nBuffer Cache：缓存磁盘块的原始数据（已逐步被Page Cache取代，但在某些场景仍用于块设备操作）\n磁盘文件系统（ext2&#x2F;ext3&#x2F;ext4）：\next2：早期非日志式文件系统，简单但易崩溃损坏。\next3：增加日志功能，提升崩溃恢复能力。\next4：支持更大文件&#x2F;分区、延迟分配等高级特性。\n\n\n伪文件系统：\nproc：虚拟文件系统，动态暴露内核状态（如 &#x2F;proc&#x2F;cpuinfo）\nsysfs：提供设备&#x2F;驱动信息的统一接口（如 &#x2F;sys&#x2F;class）\n\n\n\n3.VFS关键数据结构VFS中包含着向物理文件系统转换的一系列数据结构，Linux中VFS层依靠四个主要的数据结构来述其结构信息，分别为超级块、索引结点、目录项和文件对象。这四个数据结构作用如下：\n3.1 Superblock（超级块）\n功能：超级块(块指的是存储和管理数据的基本单位)对象由各自的文件系统实现，用来存储文件系统的信息，如块大小、块数量等。这个对象对应为文件系统超级块或者文件系统控制块，它存储在磁盘特定的扇区上。不是基于磁盘的文件系统临时生成超级块，并保存在内存中，注意：所有超级块对象都以双向循环链表的形式链接在一起被管理。\n\n用途： \n\n超级块与物理文件系统一一对应。\n在挂载时初始化，帮助管理文件系统。\n\n\n\n管理超级块的结构体如下所示：\nstruct super_block &#123;    struct list_head    s_list;               // 指向链表的指针    dev_t               s_dev;                // 设备标识符    unsigned long       s_blocksize;          // 以字节为单位的块大小    loff_t              s_maxbytes;           // 文件大小上限    struct file_system_type    *s_type;       // 文件系统类型    const struct super_operations    *s_op;   // SuperBlock 操作函数，write_inode、put_inode 等    const struct dquot_operations    *dq_op;  // 磁盘限额函数    struct dentry        *s_root;             // 根目录&#125;\n\n3.2 Inode(索引节点)\n功能：每个文件都有一个唯一的inode，存储了文件的元数据，如文件大小、权限、访问时间等。它是文件系统中文件的抽象表示，不包含文件名。\n特点：inode存储在磁盘中（伪文件系统除外），在需要的时候会被加载到内存中，具体情况如下：inode 是文件系统的元数据结构，直接存储在磁盘上，用于长期保存文件的元信息（如权限、大小、块位置等）例如在Ext4文件系统中，inode集中存放在磁盘的固定区域。当访问某个文件时，会根据具体的磁盘上的inode(也就是磁盘中的inode, 比如ext4_inode_info)，来填充VFS的创建的inode(用私有指针指一下)。\n\nVFS管理的inode结构如下所示：\nstruct inode &#123;    umode_t                 i_mode;          // 文件权限及类型    kuid_t                  i_uid;           // user id    kgid_t                  i_gid;           // group id    const struct inode_operations    *i_op;  // inode 操作函数，如 create，mkdir，lookup，rename 等    struct super_block      *i_sb;           // 所属的 SuperBlock    loff_t                  i_size;          // 文件大小    struct timespec         i_atime;         // 文件最后访问时间    struct timespec         i_mtime;         // 文件最后修改时间    struct timespec         i_ctime;         // 文件元数据最后修改时间（包括文件名称）    const struct file_operations    *i_fop;  // 文件操作函数，open、write 等    void                    *i_private;      // 文件系统的私有数据&#125;\n\n3.3 Dentry(目录项)Dentry的核心作用是在内存中建立文件名（路径）与 inode 之间的高效映射。每个 Dentry 代表路径中一个特定部分。对于“&#x2F;bin&#x2F;ls”、“&#x2F;”、“bin”和“ls”都是目录项对象。前面是两个目录，最后一个是普通文件。在路径中， 包括普通文件在内，每一个部分都是目录项对象。目录项是描述文件的逻辑属性，只存在于内存中，举个例子，当调用open()函数打开一个文件时，内核会第一时间根据文件路径到 DEntry Cache 里面寻找相应的 DEntry，找到了就直接构造一个file对象并返回。如果该文件不在缓存中，那么 VFS 会根据找到的最近目录一级一级地向下加载，直到找到相应的文件。期间 VFS 会缓存所有被加载生成的dentry。注意:一个 INode 可能被多个 DEntry 所关联，即相当于为某一文件创建了多个文件路径.\nVFS管理的Dentry结构如下所示：\nstruct dentry &#123;    struct dentry *d_parent;     // 父目录    struct qstr d_name;          // 文件名称    struct inode *d_inode;       // 关联的 inode    struct list_head d_child;    // 父目录中的子目录和文件    struct list_head d_subdirs;  // 当前目录中的子目录和文件&#125;\n\n3.4 file 文件对象虚拟文件系统最后一个主要对象是文件对象，文件对象表示进程已打开的文件，每个进程都持有一个fd[]数组，数组里面存放的是指向file结构体的指针，同一进程的不同fd可以指向同一个file对象，file是内核中的数据结构，表示一个被进程打开的文件，和进程相关联。当应用程序调用open()函数的时候，VFS 就会创建相应的file对象。注意： file会通过Dentry找到inode，file的ops集合（read，write等）其实就是inode的i_fops; 这样感觉就实现了进程和文件系统之间的解耦。\nfile结构如下所示：\nstruct file &#123;    struct path                   f_path;    struct inode                  *f_inode;    const struct file_operations  *f_op;    unsigned int                  f_flags;    fmode_t                       f_mode;    loff_t                        f_pos;    struct fown_struct            f_owner;&#125;\n\n下图为上述四个关键数据结构的关系图：\n\n4.挂载4.1 什么叫挂载挂载（Mounting） 是将存储设备（如硬盘、U盘）或文件系统（如Ext4、NTFS）关联到Linux目录树中某个目录（称为挂载点）的过程。挂载后，访问该目录实际指向目标设备或文件系统的内容，而原目录下的文件会被临时隐藏。例如，将U盘挂载到&#x2F;mnt&#x2F;usb后，访问此目录即访问U盘数据，卸载后恢复原目录内容。内核通过虚拟文件系统（VFS）管理挂载表，动态路由路径解析，实现对多文件系统的统一访问。简言之，挂载是让外部存储“接入”目录树的机制，用户通过目录操作文件，无需关心物理设备细节。\n挂载是在用户态发起mount命令，该命令执行的时候需要指定文件系统的类型（例如Ext2）和文件系统数据的位置（也就是dev）。通过这些关键信息，VFS就可以完成Ext2文件系统的初始化，并将其关联到当前已经存在的文件系统当中，也就是建立起下面所示的文件系统树。\n\n如上图所示，该系统根文件系统是Ext4文件系统，而在其&#x2F;mnt目录下面又分别挂载了Ext4文件系统和XFS文件系统。最后形成了一个由多个文件系统组成的文件系统树。\n4.2 挂载点 挂载点（Mount Point）是 Linux系统中用于将外部存储设备或文件系统接入到目录树的一个空目录。通过挂载操作，该目录会成为访问目标文件系统的入口，原有内容会被临时隐藏，转而显示被挂载设备或文件系统的内容。\n一个挂载点用一个vfsmount来表示，属于VFS层的一部分，在用户执行mount系统调用的时候会被创建，它记录了文件系统实例与目录树的关联关系，是挂载机制的核心实现，作用如下：\n\n关联挂载点与超级块：记录被挂载的超级块，其实就是知道被挂载的是哪个文件系统\n支持路径解析：当用户访问路径时，VFS 通过 vfsmount 确定目标文件系统的位置。例如，当访问&#x2F;mnt&#x2F;data&#x2F;file.txt时VFS 发现 &#x2F;mnt&#x2F;data 是挂载点（进而可以拿到超级块的信息）进而调用目标文件系统的方法继续查找要操作的文件。\n\nvfsmount结构如下所示：\nstruct vfsmount &#123;\tstruct dentry *mnt_root;\t//挂载的目录\tstruct super_block *mnt_sb;\t//指向超级块\tint mnt_flags;\tstruct mnt_idmap *mnt_idmap;&#125; __randomize_layout;\n","categories":["文件系统学习"],"tags":["VFS"]},{"title":"IPSec","url":"/2025/05/18/ipsec/","content":"IPSec1.IPSec 简介起源随着Internet的发展，越来越多的企业直接通过Internet进行互联，但由于IP协议未考虑安全性，而且Internet上有大量的不可靠用户和网络设备，所以用户业务数据要穿越这些未知网络，根本无法保证数据的安全性，数据易被伪造、篡改或窃取。因此，迫切需要一种兼容IP协议的通用的网络安全方案。为了解决上述问题，IPSec（Internet Protocol Security）应运而生。IPSec是对IP的安全性补充，其工作在IP层，为IP网络通信提供透明的安全服务。\n定义IPSec是IETF（Internet Engineering Task Force）制定的一组开放的网络安全协议。它并不是一个单独的协议，而是一系列为IP网络提供安全性的协议和服务的集合，包括认证头AH（Authentication Header）和封装安全载荷ESP（Encapsulating SecurityPayload）两个安全协议、密钥交换和用于验证及加密的一些算法等。通过这些协议，在两个设备之间建立一条IPSec隧道。数据通过IPSec隧道进行转发，实现保护数据的安全性。\n受益IPSec通过加密与验证等方式，从以下几个方面保障了用户业务数据在Internet中的安全传输：\n\n数据来源验证：接收方验证发送方身份是否合法。\n数据加密：发送方对数据进行加密，以密文的形式在Internet上传送，接收方对接收的加密数据进行解密后处理或直接转发。\n数据完整性：接收方对接收的数据进行验证，以判定报文是否被篡改。\n抗重放：接收方拒绝旧的或重复的数据包，防止恶意用户通过重复发送捕获到的数据包所进行的攻击。\n\n2.IPSec原理描述2.1IPSec 协议框架2.1.1安全联盟安全联盟SA（Security Association）是通信对等体间对某些要素的协定，它描述了对等体间如何利用安全服务（例如加密）进行安全的通信。这些要素包括对等体间使用何种安全协议、要保护的数据流特征、对等体间传输的数据的封装模式、协议采用的加密和验证算法，以及用于数据安全转换、传输的密钥和SA的生存周期等。IPSec安全传输数据的前提是在IPSec对等体（即运行IPSec协议的两个端点）之间成功建立安全联盟。IPSec安全联盟简称IPSec SA，由一个三元组来唯一标识，这个三元组包括安全参数索引SPI（Security Parameter Index）、目的IP地址和使用的安全协议号（AH或ESP）。其中，SPI是为唯一标识SA而生成的一个32位比特的数值，它被封装在AH和ESP头中。IPSec SA是单向的逻辑连接，通常成对建立（Inbound和Outbound）。因此两个IPSec对等体之间的双向通信，最少需要建立一对IPSec SA形成一个安全互通的IPSec隧道，分别对两个方向的数据流进行安全保护。另外，IPSec SA的个数还与安全协议相关。如果只使用AH或ESP来保护两个对等体之间的流量，则对等体之间就有两个SA，每个方向上一个。如果对等体同时使用了AH和ESP，那么对等体之间就需要四个SA，每个方向上两个，分别对应AH和ESP。建立IPSec SA有两种方式：手工方式和IKE方式。二者的主要差异如表所示。\n\n\n\n对比项\n手工方式建立IPSec SA\nIKE方式自动建立IPSec SA\n\n\n\n加密&#x2F;验证密钥管理\n手工配置、手动刷新，易出错\n通过DH算法动态生成并自动刷新\n\n\n密钥管理成本\n高（需人工维护所有节点密钥）\n低（自动协商和轮换）\n\n\nSPI（安全参数索引）\n手工配置\n随机生成\n\n\n生存周期\n无限制，SA永久存在（除非手动删除）\n由生存周期参数控制，SA自动过期和重建\n\n\n安全性\n低（静态密钥易被破解，无前向保密）\n高（动态密钥、支持PFS、抗重放攻击）\n\n\n适用场景\n小型网络、临时测试环境\n中小型至大型网络、生产环境\n\n\n2.1.2安全协议IPSec使用认证头AH（Authentication Header）和封装安全载荷ESP EncapsulatingSecurity Payload）两种IP传输层协议来提供认证或加密等安全服务。\n\nAH协议：AH仅支持认证功能，不支持加密功能。AH在每一个数据包的标准IP报头后面添加一个AH报文头。AH对数据包和认证密钥进行Hash计算，接收方收到带有计算结果的数据包后，执行同样的Hash计算并与原计算结果比较，传输过程中对数据的任何更改将使计算结果无效，这样就提供了数据来源认证和数据完整性校验。AH协议的完整性验证范围为整个IP报文。\n\nESP协议：ESP支持认证和加密功能。ESP在每一个数据包的标准IP报头后面添加一个ESP报文头，并在数据包后面追加一个ESP尾（ESP Trailer和ESP Auth data）。与AH不同的是，ESP将数据中的有效载荷进行加密后再封装到数据包中，以保证数据的机密性，但ESP没有对IP头的内容进行保护，除非IP头被封装在ESP内部（采用隧道模式）。\n\n\nAH协议与ESP协议的比较如下所示：\n\n\n\n安全特性\nAH (认证头)\nESP (封装安全载荷)\n\n\n\n协议号\n51\n50\n\n\n数据完整性校验\n支持（验证整个IP报文）\n支持（传输模式：不验证IP头；隧道模式：验证整个IP报文）\n\n\n数据源验证\n支持\n支持\n\n\n数据加密\n不支持\n支持\n\n\n防报文重放攻击\n支持\n支持\n\n\nNAT-T (NAT穿越)\n不支持\n支持\n\n\nAH报文头结构\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| 下一个头部 (8 bits) | 载荷长度 (8 bits) |  保留 (16 bits)         |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+|                   安全参数索引 (SPI, 32 bits)                   |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+|                   序列号 (Sequence Number, 32 bits)            |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+|                                                               ||                认证数据 (可变长度，32 bits的整数倍)               ||                                                               |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\n AH 报文头字段含义\n\n\n\n字段名\n长度\n含义\n\n\n\n下一头部\n8 bits\n标识 AH 报文头后面的负载类型： - 传输模式：被保护的上层协议（TCP&#x2F;UDP）或 ESP 协议编号 - 隧道模式：IP 协议或 ESP 协议编号（当 AH 与 ESP 同时使用时，下一头部为 ESP 报文头）\n\n\n负载长度\n8 bits\n以 32 比特为单位的 AH 报文头长度减 2（缺省值：4）\n\n\n保留字段\n16 bits\n保留将来使用，缺省为 0\n\n\nSPI\n32 bits\nIPSec 安全参数索引，唯一标识安全联盟（SA）\n\n\n序列号\n32 bits\n从 1 开始的单向递增计数器，防止重放攻击\n\n\n认证数据\n变长字段（32 比特整数倍，通常 96 bits）\n包含完整性校验值（ICV），用于接收方校验数据完整性。认证算法：- ✅ 推荐：SHA2、SM3- ⚠️ 不安全：MD5、SHA1（存在安全隐患）\n\n\nESP 报文结构\n+-----------------------------------------------+ &lt;-- ESP头部| 安全参数索引（SPI）                              |+-----------------------------------------------+| 序列号                                         |+-----------------------------------------------+ &lt;-- 加密部分开始|                                               || 负载数据（Payload，变长）                        ||                                               |+-----------------------------------------------+| 填充字段（0～255字节 Padding）                   |+-----------------------------------------------+| 填充长度（1B） | 下一头部（1B）                   |+-----------------------------------------------+ &lt;-- ESP尾部（加密部分结束）|                                               || 认证数据（ICV，完整性校验值，变长                  ||                                               |+-----------------------------------------------+ &lt;-- ESP认证部分\n\n ESP 报文头字段含义\n\n\n\n字段名\n长度\n含义\n\n\n\nSPI\n32 bits\nIPSec 安全参数索引，唯一标识安全联盟（SA）\n\n\n序列号\n32 bits\n从 1 开始的单向递增计数器，防止重放攻击\n\n\n负载数据\n变长\n原始 IP 报文中的可变长度数据内容（保护内容类型由下一头部字段标识）\n\n\n填充字段\n0-255 字节\n用于补齐加密算法要求的块长度\n\n\n填充长度\n8 bits\n表示填充字段的字节数（0 表示无填充）\n\n\n下一头部\n8 bits\n标识下一个负载类型：- 传输模式：上层协议编号（如 TCP&#x3D;6&#x2F;UDP&#x3D;17）- 隧道模式：IP 协议（IPv4&#x3D;4&#x2F;IPv6&#x3D;41）\n\n\n认证数据\n变长\n完整性校验值（ICV），需 32 位对齐\n\n\n2.1.3封装模式封装模式是指将AH或ESP相关的字段插入到原始IP报文中，以实现对报文的认证和加密，封装模式有传输模式和隧道模式两种。\n传输模式\n在传输模式中，AH头或ESP头被插入到IP头与传输层协议头之间，保护TCP&#x2F;UDP&#x2F;ICMP负载。由于传输模式未添加额外的IP头，所以原始报文中的IP地址在加密后报文的IP头中可见。以TCP报文为例，原始报文经过传输模式封装后，报文格式如下所示。\n\n隧道模式\n在隧道模式下，AH头或ESP头被插到原始IP头之前，另外生成一个新的报文头放到AH头或ESP头之前，保护IP头和负载。以TCP报文为例，原始报文经隧道模式封装后的报文结构如下图所示。\n\n隧道模式下，与AH协议相比，ESP协议的完整性验证范围不包括新IP头，无法保证新IP头的安全。\n传输模式和隧道模式比较\n传输模式和隧道模式的区别在于：\n\n从安全性来讲，隧道模式优于传输模式。它可以完全地对原始IP数据包进行验证和加密。隧道模式下可以隐藏内部IP地址，协议类型和端口。\n从性能来讲，隧道模式因为有一个额外的IP头，所以它将比传输模式占用更多带宽。\n从场景来讲，传输模式主要应用于两台主机或一台主机和一台VPN网关之间通信；隧道模式主要应用于两台VPN网关之间或一台主机与一台VPN网关之间的通信。当安全协议同时采用AH和ESP时，AH和ESP协议必须采用相同的封装模式。\n\n2.1.4 加密和验证IPSec提供了两种安全机制：加密和验证。加密机制保证数据的机密性，防止数据在传输过程中被窃听；验证机制能保证数据真实可靠，防止数据在传输过程中被仿冒和篡改。\n加密\nIPSec采用对称加密算法对数据进行加密和解密。如下图所示，数据发送方和接收方使用相同的密钥进行加密、解密。\n用于加密和解密的对称密钥可以手工配置，也可以通过IKE协议自动协商生成。常用的对称加密算法包括：数据加密标准DES（Data Encryption Standard）、3DES（Triple Data Encryption Standard）、先进加密标准AES（Advanced EncryptionStandard）国密算法（SM1和SM4）。其中，DES和3DES算法安全性低，存在安全风险，不推荐使用。\n验证\nIPSec的加密功能，无法验证解密后的信息是否是原始发送的信息或完整。IPSec采用HMAC（Keyed-Hash Message Authentication Code）功能，比较完整性校验值ICV进行数据包完整性和真实性验证。通常情况下，加密和验证通常配合使用。如图所示，在IPSec发送方，加密后的报文通过验证算法和对称密钥生成完整性校验值ICV，IP报文和完整性校验值ICV同时发给对端；在IPSec接收方，使用相同的验证算法和对称密钥对加密报文进行处理，同样得到完整性校验值ICV，然后比较完整性校验值ICV进行数据完整性和真实性验证，验证不通过的报文直接丢弃，验证通过的报文再进行解密。\n\n同加密一样，用于验证的对称密钥也可以手工配置，或者通过IKE协议自动协商生成。常用的验证算法包括：消息摘要MD5（Message Digest 5）、安全散列算法SHA1（Secure Hash Algorithm 1）、SHA2、国密算法SM3（Senior Middle 3）。其中，MD5、SHA1算法安全性低，存在安全风险，不推荐使用。\n2.1.5  密钥交换使用对称密钥进行加密、验证时，如何安全地共享密钥是一个很重要的问题。有两种方法解决这个问题：\n\n带外共享密钥在发送、接收设备上手工配置静态的加密、验证密钥。双方通过带外共享的方式（例如通过电话或邮件方式）保证密钥一致性。这种方式的缺点是安全性低，可扩展性差，在点到多点组网中配置密钥的工作量成倍增加。另外，为提升网络安全性需要周期性修改密钥，这种方式下也很难实施。\n使用一个安全的密钥分发协议通过IKE协议自动协商密钥。IKE采用DH算法在不安全的网络上安全地分发密钥。这种方式配置简单，可扩展性好，特别是在大型动态的网络环境下此优点更加突出。同时，通信双方通过交换密钥交换材料来计算共享的密钥，即使第三方截获了双方用于计算密钥的所有交换数据，也无法计算出真正的密钥，这样极大地提高了安全性。\n\nIKE 协议因特网密钥交换IKE（Internet Key Exchange）协议建立在Internet安全联盟和密钥管理协议ISAKMP定义的框架上，是基于UDP（User Datagram Protocol）的应用层协议。它为IPSec提供了自动协商密钥、建立IPSec安全联盟的服务，能够简化IPSec的配置和维护工作。IKE与IPSec的关系如图所示，对等体之间建立一个IKE SA完成身份验证和密钥信息交换后，在IKE SA的保护下，根据配置的AH&#x2F;ESP安全协议等参数协商出一对IPSecSA。此后，对等体间的数据将在IPSec隧道中加密传输。IKE SA是一个双向的逻辑连接，两个对等体间只建立一个IKE SA。\n\nIKE安全机制\nIKE具有一套自保护机制，可以在网络上安全地认证身份、分发密钥、建立IPSec SA：\n\n身份认证身份认证确认通信双方的身份（对等体的IP地址或名称），包括预共享密钥PSK（pre-shared key）认证、数字证书RSA（rsa-signature）认证和数字信封认证。在预共享密钥认证中，通信双方采用共享的密钥对报文进行Hash计算，判断双方的计算结果是否相同。如果相同，则认证通过；否则认证失败。当有1个对等体对应多个对等体时，需要为每个对等体配置预共享的密钥。该方法在小型网络中容易建立，但安全性较低。在数字证书认证中，通信双方使用CA证书进行数字证书合法性验证，双方各有自己的公钥（网络上传输）和私钥（自己持有）。发送方对原始报文进行Hash计算，并用自己的私钥对报文计算结果进行加密，生成数字签名。接收方使用发送方的公钥对数字签名进行解密，并对报文进行Hash计算，判断计算结果与解密后的结果是否相同。如果相同，则认证通过；否则认证失败。使用数字证书安全性高，但需要CA来颁发数字证书，适合在大型网络中使用。在数字信封认证中，发送方首先随机产生一个对称密钥，使用接收方的公钥对此对称密钥进行加密（被公钥加密的对称密钥称为数字信封），发送方用对称密钥加密报文，同时用自己的私钥生成数字签名。接收方用自己的私钥解密数字信封得到对称密钥，再用对称密钥解密报文，同时根据发送方的公钥对数字签名进行解密，验证发送方的数字签名是否正确。如果正确，则认证通过；否则认证失败。数字信封认证用于设备需要符合国家密码管理局要求时使用，此认证方法只能在IKEv1的主模式协商过程中支持。IKE支持的认证算法有：MD5、SHA1、SHA2-256、SHA2-384、SHA2-512、SM3。\n\n身份保护身份数据在密钥产生之后加密传送，实现了对身份数据的保护。IKE支持的加密算法有：DES、3DES、AES-128、AES-192、AES-256、SM1和SM4。\n\nDHDH是一种公共密钥交换方法，它用于产生密钥材料，并通过ISAKMP消息在发送和接收设备之间进行密钥材料交换。然后，两端设备各自计算出完全相同的对称密钥。该对称密钥用于计算加密和验证的密钥。在任何时候，通信双方都不交换真正的密钥。DH密钥交换是IKE的精髓所在。\n\nPFS完善的前向安全性PFS（Perfect Forward Secrecy）通过执行一次额外的DH交换，确保即使IKE SA中使用的密钥被泄露，IPSec SA中使用的密钥也不会受到损害。\n\n\n2.2IPSec 基本原理IPSec通过在IPSec对等体间建立双向安全联盟形成一个安全互通的IPSec隧道，并通过定义IPSec保护的数据流将要保护的数据引入该IPSec隧道，然后对流经IPSec隧道的数据通过安全协议进行加密和验证，进而实现在Internet上安全传输指定的数据。IPSec安全联盟可以手工建立，也可以通过IKEv1或IKEv2协议自动协商建立。本文重点介绍如何定义IPSec保护的数据流、IKE自动协商建立安全联盟的过程。\n2.2.1 定义 IPSec 保护的数据流IPSec是基于定义的感兴趣流触发对特定数据的保护，至于什么样的数据是需要IPSec保护的，可以通过以下两种方式定义。其中IPSec感兴趣流即需要IPSec保护的数据流。\n\nACL方式手工方式和IKE自动协商方式建立的IPSec隧道是由ACL来指定要保护的数据流范围，筛选出需要进入IPSec隧道的报文，ACL规则允许（permit）的报文将被保护，未匹配任何permit规则的报文将不被保护。这种方式可以利用ACL的丰富配置功能，根据IP地址、端口、协议类型等对报文进行过滤进而灵活制定IPSec的保护方法。\n路由方式通过IPSec虚拟隧道接口建立IPSec隧道，将所有路由到IPSec虚拟隧道接口的报文都进行IPSec保护，根据该路由的目的地址确定哪些数据流需要IPSec保护。其中IPSec虚拟隧道接口是一种三层逻辑接口。路由方式具有以下优点：\n通过路由将需要IPSec保护的数据流引到虚拟隧道接口，不需使用ACL定义待\n加&#x2F;解密的流量特征，简化了IPSec配置的复杂性。\n支持动态路由协议。\n通过GRE over IPSec支持对组播流量的保护。\n\n\n\n2.2.2 IKEv1 协商安全联盟的过程IKEv1 协商阶段1\nIKEv1协商阶段1的目的是建立IKE SA。IKE SA建立后对等体间的所有ISAKMP（一个框架 IKE是一种实现）消息都将通过加密和验证，这条安全通道可以保证IKEv1第二阶段的协商能够安全进行。IKEv1协商阶段1支持两种协商模式：主模式（Main Mode）和野蛮模式（AggressiveMode）。主模式包含三次双向交换，用到了六条ISAKMP信息，协商过程如下图所示。这三次交换分别是：\n\n消息①和②用于提议交换发起方发送一个或多个IKE安全提议，响应方查找最先匹配的IKE安全提议，并将这个IKE安全提议回应给发起方。匹配的原则为协商双方具有相同的加密算法、认证算法、认证方法和DH组标识。\n消息③和④用于密钥信息交换\n双方交换DH(一种密钥交换算法，不暴露私钥的情况下，计算出一个共享密钥)公共值和nonce(一个随机值)值，用于IKE SA的认证和加密密钥在这个阶段产生。消息⑤和⑥用于身份和认证信息交换（双方使用生成的密钥发送信息），双方进行身份认证和对整个主模式交换内容的认证。\n\n野蛮模式只用到三条信息，前两条消息①和②用于协商IKE安全提议，交换DH公共值、必需的辅助信息以及身份信息并且消息②中还包括响应方发送身份信息供发起方认证，消息③用于响应方认证发起方。IKEv1协商阶段1的协商过程如下图所示。\n\n与主模式相比，野蛮模式减少了交换信息的数目，提高了协商的速度，但是没有对身份信息进行加密保护。\nIKEv1 协商阶段 2\nIKEv1协商阶段2的目的就是建立用来安全传输数据的IPSec SA，并为数据传输衍生出密钥。这一阶段采用快速模式（Quick Mode）。该模式使用IKEv1协商阶段1中生成的密钥对ISAKMP消息的完整性和身份进行验证，并对ISAKMP消息进行加密，故保证了交换的安全性。IKEv1协商阶段2的协商过程如下图所示。\n\nIKEv1协商阶段2通过三条ISAKMP消息完成双方IPSec SA的建立：\n\n协商发起方发送本端的安全参数和身份认证信息。安全参数包括被保护的数据流和IPSec安全提议等需要协商的参数。身份认证信息包括第一阶段计算出的密钥和第二阶段产生的密钥材料等，可以再次认证对等体。\n协商响应方发送确认的安全参数和身份认证信息并生成新的密钥。IPSec SA数据传输需要的加密、验证密钥由第一阶段产生的密钥、SPI、协议等参数衍生得出，以保证每个IPSec SA都有自己独一无二的密钥。如果启用PFS，则需要再次应用DH算法计算出一个共享密钥，然后参与上述计算，因此在参数协商时要为PFS协商DH密钥组。\n发送方发送确认信息，确认与响应方可以通信，协商结束。\n\n2.2.3 IKEv2 协商安全联盟的过程采用IKEv2协商安全联盟比IKEv1协商过程要简化的多。要建立一对IPSec SA，IKEv1需要经历两个阶段：“主模式＋快速模式”或者“野蛮模式＋快速模式”，前者至少需要交换9条消息，后者也至少需要6条消息。而IKEv2正常情况使用2次交换共4条消息就可以完成一对IPSec SA的建立，如果要求建立的IPSec SA大于一对时，每一对IPSec SA只需额外增加1次创建子SA交换，也就是2条消息就可以完成。IKEv2定义了三种交换：初始交换（Initial Exchanges）、创建子SA交换（Create_Child_SA Exchange）以及通知交换（Informational Exchange）。\n初始交换\n正常情况下，IKEv2通过初始交换就可以完成第一对IPSec SA的协商建立。IKEv2初始交换对应IKEv1的第一阶段，初始交换包含两次交换四条消息，如下图所示。\n消息①和②属于第一次交换（称为IKE_SA_INIT交换），以明文方式完成IKE SA的参数协商，包括协商加密和验证算法，交换临时随机数和DH交换。IKE_SA_INIT交换后生成一个共享密钥材料，通过这个共享密钥材料可以衍生出IPSec SA的所有密钥。消息③和④属于第二次交换（称为IKE_AUTH交换），以加密方式完成身份认证、对前两条信息的认证和IPSec SA的参数协商。IKEv2支持RSA签名认证、预共享密钥认证以及扩展认证方法EAP（Extensible Authentication Protocol）。发起者通过在消息3中省去认证载荷来表明需要使用EAP认证。\n创建子 SA 交换\n当一个IKE SA需要创建多对IPSec SA时，需要使用创建子SA交换来协商多于一对的IPSec SA。另外，创建子SA交换还可以用于IKE SA的重协商。创建子SA交换包含一个交换两条消息，对应IKEv1协商阶段2，交换的发起者可以是初始交换的协商发起方，也可以是初始交换的协商响应方。创建子SA交换必须在初始交换完成后进行，交换消息由初始交换协商的密钥进行保护。类似于IKEv1，如果启用PFS，创建子SA交换需要额外进行一次DH交换，生成新的密钥材料。生成密钥材料后，子SA的所有密钥都从这个密钥材料衍生出来。\n通知交换\n运行IKE协商的两端有时会传递一些控制信息，例如错误信息或者通告信息，这些信息在IKEv2中是通过通知交换完成的，如下图所示。通知交换必须在IKE SA保护下进行，也就是说通知交换只能发生在初始交换之后。控制信息可能是IKE SA的，那么通知交换必须由该IKE SA来保护进行；也可能是某子SA的，那么该通知交换必须由生成该子SA的IKE SA来保护进行。\n\n","categories":["网络协议学习"],"tags":["IPSec"]},{"title":"socket系统调用","url":"/2025/05/13/socket%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/","content":"简介socket 是网络编程中最基本的系统调用之一，用于创建一个网络通信的“端点”（即套接字，socket）。\n一、函数原型int socket(int domain, int type, int protocol);\n\n\n\n\n参数\n说明\n\n\n\ndomain\n协议族，比如：AF_INET 表示 IPv4\n\n\ntype\n套接字类型，比如：SOCK_STREAM 表示 TCP\n\n\nprotocol\n指定使用的协议，通常填 0 让系统自动选择\n\n\n二、函数调用流程用户态程序调用 socket()        ↓glibc 中封装的socket接口        ↓内部通过 syscall 指令        ↓进入内核，执行 sys_socket()\n三、代码分析1. glibc层代码分析代码位置：glibc-2.40\\sysdeps\\unix\\sysv\\linux\\socket.c\nint __socket (int fd, int type, int domain)&#123;#ifdef __ASSUME_SOCKET_SYSCALL //是否支持单独的系统调用号，肯定支持  return INLINE_SYSCALL_CALL (socket, fd, type, domain);#else\t//32位的处理器会走这个分支  return SOCKETCALL (socket, fd, type, domain);#endif&#125;libc_hidden_def (__socket)//暴露给外部程序的符号为socket() 其实是__socket()的别名weak_alias (__socket, socket)\n\n用户应用程序调用socket()实际调用的的是上述glibc中的__socket，在__socket中 INLINE_SYSCALL_CALL宏经过一系列展开后变成宏__INLINE_SYSCALL4 ，这个宏会进一步再展开，如下所示：\n#define __INLINE_SYSCALL4(name, a1, a2, a3, a4) \\  INLINE_SYSCALL (name, 4, a1, a2, a3, a4)\n\n上述的INLINE_SYSCALL 展开，结果如下所示：\n#define INLINE_SYSCALL(name, nr, args...)\t\t\t\t\\  (&#123;\t//sc_ret为系统调用的返回值    long int sc_ret = INTERNAL_SYSCALL (name, nr, args);\t//对返回值好像要简单检查一下    __glibc_unlikely (INTERNAL_SYSCALL_ERROR_P (sc_ret))\t\t\\    ? SYSCALL_ERROR_LABEL (INTERNAL_SYSCALL_ERRNO (sc_ret))\t\t\\    : sc_ret;\t\t\t\t\t\t\t\t\\  &#125;)\n\nINTERNAL_SYSCALL 进一步在展开，会变成了internal_syscall3\n这里举个例子，例如，未展开前为INTERNAL_SYSCALL(socket, 3, AF_INET, SOCK_STREAM, 0) 展开后会变成\ninternal_syscall3(__NR_socket, AF_INET, SOCK_STREAM, 0)，如果在x86架构中宏__NR_socket为41\n在glibc-2.40\\sysdeps\\unix\\sysv\\linux\\x86_64\\64\\arch-syscall.h 中有定义\n#define __NR_socket 41\n\n总之，上述宏经过一系列展开后变成了如下函数，其中number为系统调用号，arg1, arg2, arg3 为传入的参数\n#define internal_syscall3(number, arg1, arg2, arg3)\t\t\t\\(&#123;\t\t\t\t\t\t\t\t\t\\    unsigned long int resultvar;\t\t\t\t\t\\    TYPEFY (arg3, __arg3) = ARGIFY (arg3);\t\t\t \t\\    TYPEFY (arg2, __arg2) = ARGIFY (arg2);\t\t\t \t\\    TYPEFY (arg1, __arg1) = ARGIFY (arg1);\t\t\t \t\\    register TYPEFY (arg3, _a3) asm (&quot;rdx&quot;) = __arg3;\t\t\t\\    register TYPEFY (arg2, _a2) asm (&quot;rsi&quot;) = __arg2;\t\t\t\\    register TYPEFY (arg1, _a1) asm (&quot;rdi&quot;) = __arg1;\t\t\t\\    asm volatile (\t\t\t\t\t\t\t\\    &quot;syscall\\n\\t&quot;\t\t\t\t\t\t\t\\    : &quot;=a&quot; (resultvar)\t\t\t\t\t\t\t\\    : &quot;0&quot; (number), &quot;r&quot; (_a1), &quot;r&quot; (_a2), &quot;r&quot; (_a3)\t\t\t\\    : &quot;memory&quot;, REGISTERS_CLOBBERED_BY_SYSCALL);\t\t\t\\    (long int) resultvar;\t\t\t\t\t\t\\&#125;)\n\n上述代码的作用是将系统调用号和 3 个参数分别放入规定的寄存器（RAX, RDI, RSI, RDX），然后执行 syscall 指令，并将返回值保存到 resultvar：\n“memory”, REGISTERS_CLOBBERED_BY_SYSCALL 的意思是告诉编译器不要优化这段代码\n下面附上x86-64 Linux 的 syscall 调用约定传参的寄存器\n\n\n\n参数\n寄存器\n\n\n\nsyscall 编号\nRAX\n\n\n参数1\nRDI\n\n\n参数2\nRSI\n\n\n参数3\nRDX\n\n\n参数4\nR10\n\n\n参数5\nR8\n\n\n参数6\nR9\n\n\n2.内核代码分析执行上述syscall指令后CPU 会根据 MSR 寄存器（Model Specific Registers）跳转到系统调用函数，例如，x86架构则会进入到系统调用的统一入口函数entry_SYSCALL_64\nentry_SYSCALL_64函数的注册（也就把地址写入MSR寄存器）在syscall_init中完成代码如下：\nvoid syscall_init(void)&#123;\twrmsr(MSR_STAR, 0, (__USER32_CS &lt;&lt; 16) | __KERNEL_CS);\t//把entry_SYSCALL_64 的地址写入MSR_LSTAR寄存器\twrmsrl(MSR_LSTAR, (unsigned long)entry_SYSCALL_64); \t...&#125;\n\n上述syscall_init 函数在start_kernel（）中被调用\n接下里看一下entry_SYSCALL_64的逻辑，\nSYM_CODE_START(entry_SYSCALL_64)\tUNWIND_HINT_EMPTY\t//这个是切换GS寄存器，这个寄存器是访问per-cpu变量的基址task_struct结构就依赖这个寄存器间接获得\tswapgs\t/* tss.sp2 is scratch space. */\t//将当前栈指针保存\tmovq\t%rsp, PER_CPU_VAR(cpu_tss_rw + TSS_sp2)\t//切换页表\tSWITCH_TO_KERNEL_CR3 scratch_reg=%rsp\t//切换当前栈指针到当前 CPU 的内核栈顶指针\tmovq\tPER_CPU_VAR(cpu_current_top_of_stack), %rspSYM_INNER_LABEL(entry_SYSCALL_64_safe_stack, SYM_L_GLOBAL)\t/* Construct struct pt_regs on stack */\t//把用户态的一些信息入栈（貌似就是pt_regs）\tpushq\t$__USER_DS\t\t\t\t/* pt_regs-&gt;ss */\tpushq\tPER_CPU_VAR(cpu_tss_rw + TSS_sp2)\t/* pt_regs-&gt;sp */\tpushq\t%r11\t\t\t\t\t/* pt_regs-&gt;flags */\tpushq\t$__USER_CS\t\t\t\t/* pt_regs-&gt;cs */\tpushq\t%rcx\t\t\t\t\t/* pt_regs-&gt;ip */SYM_INNER_LABEL(entry_SYSCALL_64_after_hwframe, SYM_L_GLOBAL)\t//这里存了系统调用号\tpushq\t%rax\t\t\t\t\t/* pt_regs-&gt;orig_ax */\t//其他寄存器的信息继续保存到栈中\tPUSH_AND_CLEAR_REGS rax=$-ENOSYS\t/* IRQs are off. */\t//把系统调用号放入 rdi → 作为函数的第 1 个参数\tmovq\t%rax, %rdi\t//把 pt_regs 地址放入 rsi → 作为第 2 个参数\tmovq\t%rsp, %rsi\t//调用do_syscall_64\tcall\tdo_syscall_64\t\t/* returns with IRQs disabled */\t...\tSYM_CODE_END(entry_SYSCALL_64)\n\n在用户执行 syscall 指令后，CPU 跳转到entry_SYSCALL_64，完成从用户态到内核态的切换、栈构造、参数准备，并调用 C 函数 do_syscall_64() 来处理系统调用。\n接下来看一下上述汇编代码中调用do_syscall_64 代码位于arch\\x86\\entry\\common.c中\n#ifdef CONFIG_X86_64__visible noinstr void do_syscall_64(unsigned long nr, struct pt_regs *regs)&#123;\t//这里开启了中断（进入系统调用前要先关中断在哪里没找到，好像sycall后会自动关）追踪，安全相关\tnr = syscall_enter_from_user_mode(regs, nr);\t//禁止插桩，\tinstrumentation_begin();\t//检查系统调用号是否在合法范围\tif (likely(nr &lt; NR_syscalls)) &#123;\t\tnr = array_index_nospec(nr, NR_syscalls);\t\t//nr存的是系统调用好，从系统调用表中找到对应的处理函数，然后将\t\t//返回值存入到regs-&gt;ax寄存器\t\tregs-&gt;ax = sys_call_table[nr](regs);        //32位#ifdef CONFIG_X86_X32_ABI\t&#125; else if (likely((nr &amp; __X32_SYSCALL_BIT) &amp;&amp;\t\t\t  (nr &amp; ~__X32_SYSCALL_BIT) &lt; X32_NR_syscalls)) &#123;\t\tnr = array_index_nospec(nr &amp; ~__X32_SYSCALL_BIT,\t\t\t\t\tX32_NR_syscalls);\t\tregs-&gt;ax = x32_sys_call_table[nr](regs);#endif\t&#125;\tinstrumentation_end();\tsyscall_exit_to_user_mode(regs);&#125;#endif\n\n上述代码中最关键的就是regs-&gt;ax = sys_call_table[nr](regs)找到对应的系统调用函数，并传入pt_regs，pt_regs保存了参数和用户的一些信息。\nsys_call_table[]就是一个函数指针，每个元素指向具体的函数实现，定义如下所示:\nasmlinkage const sys_call_ptr_t sys_call_table[__NR_syscall_max+1] = &#123;\t/*\t * Smells like a compiler bug -- it doesn&#x27;t work\t * when the &amp; below is removed.\t */\t[0 ... __NR_syscall_max] = &amp;__x64_sys_ni_syscall,//下面这个头文件貌似是编译生成的，include进来后就替换了上面的默认值#include &lt;asm/syscalls_64.h&gt;&#125;;\n\n上述 &lt;asm/syscalls_64.h&gt;是在编译过程中生成的，具体的流程如下：\nsyscall_64.tbl   ↓（作为输入）syscalltbl.sh 脚本   ↓（生成）syscalls_64.h   ↓（#include）用于填充 sys_call_table[]\n上述流程在\\arch\\x86\\entry\\syscalls中有体现。下面展示了部分syscall_64.tbl中的内容\n0\tcommon\tread\t\t\tsys_read1\tcommon\twrite\t\t\tsys_write2\tcommon\topen\t\t\tsys_open3\tcommon\tclose\t\t\tsys_close·········41\tcommon\tsocket\t\t\tsys_socket·········440\tcommon\tprocess_madvise\t\tsys_process_madvise\n\n系统调用号 41 对应的函数指针在 sys_call_table[]被syscalltbl.sh 处理后，最终指向 __x64_sys_socket 这个函数，而这个函数和SYSCALL_DEFINE3(socket, int, family, int, type, int, protocol) 宏展开后是一个函数！\n","categories":["网络协议栈源码学习"],"tags":["socket"]},{"title":"sock的创建与初始化","url":"/2025/05/24/sock%E7%9A%84%E5%88%9B%E5%BB%BA%E4%B8%8E%E5%88%9D%E5%A7%8B%E5%8C%96/","content":"以IPv4协议族为例，当用户态执行socket系统调用后，会调用到inet_create(),在inet_create()中会创建与socket关联的sock结构体，具体代码如下：\nstatic int inet_create(struct net *net, struct socket *sock, int protocol,\t\t       int kern)&#123;    .....\t//注意： 这里申请一个sock结构，这个sock结构可以理解为传输层协议和socket之间的一个中间层\t//对上提供socket层的结构，\t//对下与具体的协议相关\t//kern 标识这个套接字是否是内核创建的\tsk = sk_alloc(net, PF_INET, GFP_KERNEL, answer_prot, kern);\tif (!sk)\t\tgoto out;    .....\t//这里初始化了上面申请的sock结构体的各个字段\tsock_init_data(sock, sk);    .....&#125;\n\nsk_alloc()上述sk_alloc()其实就是使用slab分配其分配了prot-&gt;size大小的的内存，也就是说分配了一个比sock结构体size还要大的内存，举个例子，如果是TCP协议，则分配的大小为sizeof(tcp_sock),也就是说tcp_sock内嵌了sock结构体，类似继承的关系，关系如下图所示：\n\n接下来具体看一下sk_alloc()的实现：\nstruct sock *sk_alloc(struct net *net, int family, gfp_t priority,\t\t      struct proto *prot, int kern)&#123;\tstruct sock *sk;\t//调用slab 分配一个sk结构体，注意这个结构体的大小取决与prot参数的size字段\t//__GFP_ZERO表示为内存申请后需要清零的标志位\tsk = sk_prot_alloc(prot, priority | __GFP_ZERO, family);\tif (sk) &#123;\t\t//设置协议族\t\tsk-&gt;sk_family = family;\t\t/*\t\t * See comment in struct sock definition to understand\t\t * why we need sk_prot_creator -acme\t\t */\t\t//这里很关键，将具体协议的prot关联到了sock上\t\tsk-&gt;sk_prot = sk-&gt;sk_prot_creator = prot;\t\t//记录是否是内核创建的\t\tsk-&gt;sk_kern_sock = kern;\t\tsock_lock_init(sk);\t\t//如果是用户进程创建的，就增加网络命名空间的引用计数\t\tsk-&gt;sk_net_refcnt = kern ? 0 : 1;\t\t//更新当前core上所有活跃套接字的引用计数。\t\tif (likely(sk-&gt;sk_net_refcnt)) &#123;\t\t\tget_net_track(net, &amp;sk-&gt;ns_tracker, priority);\t\t\tsock_inuse_add(net, 1);\t\t&#125; else &#123;\t\t\t__netns_tracker_alloc(net, &amp;sk-&gt;ns_tracker,\t\t\t\t\t      false, priority);\t\t&#125;\t\t//将sock与网络命名空间关联\t\tsock_net_set(sk, net);\t\t//发送缓冲区引用计数加1\t\trefcount_set(&amp;sk-&gt;sk_wmem_alloc, 1);\t\tmem_cgroup_sk_alloc(sk);\t\tcgroup_sk_alloc(&amp;sk-&gt;sk_cgrp_data);\t\tsock_update_classid(&amp;sk-&gt;sk_cgrp_data);\t\tsock_update_netprioidx(&amp;sk-&gt;sk_cgrp_data);\t\tsk_tx_queue_clear(sk);\t&#125;\treturn sk;&#125;\n\n上述代码中调用sk_prot_alloc() 根据不同的prot(也就是不同的协议)申请sock，同时设置了__GFP_ZERO 标志，表示需要将申请的内存memset，sk_prot_alloc() 的具体实现如下：\nstatic struct sock *sk_prot_alloc(struct proto *prot, gfp_t priority,\t\tint family)&#123;\tstruct sock *sk;\tstruct kmem_cache *slab;\t//从slab分配器中拿一个结构体，这个slabchace是inet_init中初始化的\tslab = prot-&gt;slab;\tif (slab != NULL) &#123;\t\tsk = kmem_cache_alloc(slab, priority &amp; ~__GFP_ZERO);\t\tif (!sk)\t\t\treturn sk;\t\t//是否需要memset，可以看到这里的大小是objsize\t\tif (want_init_on_alloc(priority))\t\t\tsk_prot_clear_nulls(sk, prot-&gt;obj_size);\t&#125; else\t//如果没使用slab就用kmalloc，kamlloc不也是slab吗？\t\tsk = kmalloc(prot-&gt;obj_size, priority);\tif (sk != NULL) &#123;\t\t//安全相关\t\tif (security_sk_alloc(sk, family, priority))\t\t\tgoto out_free;\t\t//增加引用计数\t\tif (!try_module_get(prot-&gt;owner))\t\t\tgoto out_free_sec;\t&#125;\treturn sk;out_free_sec:\tsecurity_sk_free(sk);out_free:\tif (slab != NULL)\t\tkmem_cache_free(slab, sk);\telse\t\tkfree(sk);\treturn NULL;&#125;\n\n从上述代码可知是通过slab = prot-&gt;slab;获取了一个slab对象，这个slab管理的结构体大小是inet_init()中调用proto_register()创建slab时候确定的，具体函数如下所示：\nint proto_register(struct proto *prot, int alloc_slab)&#123;\t......\tif (alloc_slab) &#123;\t\tprot-&gt;slab = kmem_cache_create_usercopy(prot-&gt;name,\t\t\t\t\tprot-&gt;obj_size, 0,\t\t\t\t\tSLAB_HWCACHE_ALIGN | SLAB_ACCOUNT |\t\t\t\t\tprot-&gt;slab_flags,\t\t\t\t\tprot-&gt;useroffset, prot-&gt;usersize,\t\t\t\t\tNULL);\t&#125;\t.......&#125;\n\n可以看到在上面创建slab缓存时，指定的size大小为prot-&gt;obj_size，例如tcp协议的obj_size则为sizeof(tcp_sock)结构体的大小。注意到上述创建slab缓存使用的接口是kmem_cache_create_usercopy，这个usercopy的意义是允许指定对象拷贝到用户空间的内存区域。prot-&gt;useroffset指的是对象中允许拷贝到用户空间的数据区域的偏移。prot-&gt;usersize指的是允许拷贝到用户空间的数据区域的大小。（tcp等协议这个字段好像都是空）\nsock_init_data()上述创建了sock结构体后紧接着就会调用sock_init_data完成初始化，sock_init_data中先从socket结构体中关联的inode中获取uid然后调用sock_init_data_uid()完成初始化，上述两个函数的代码如下：\nvoid sock_init_data(struct socket *sock, struct sock *sk)&#123;\t//注意：这里的uid是在创建socket和inode的时候设置的\t//i_uid用于表示与该 inode 关联的文件或对象的所有者用户ID\tkuid_t uid = sock ?\t\tSOCK_INODE(sock)-&gt;i_uid :\t\tmake_kuid(sock_net(sk)-&gt;user_ns, 0);\tsock_init_data_uid(sock, sk, uid);&#125;\n\nvoid sock_init_data_uid(struct socket *sock, struct sock *sk, kuid_t uid)&#123;\tsk_init_common(sk);\tsk-&gt;sk_send_head\t=\tNULL;\ttimer_setup(&amp;sk-&gt;sk_timer, NULL, 0);\tsk-&gt;sk_allocation\t=\tGFP_KERNEL;\t//设置接收和发送默认缓冲区大小\tsk-&gt;sk_rcvbuf\t\t=\tREAD_ONCE(sysctl_rmem_default);\tsk-&gt;sk_sndbuf\t\t=\tREAD_ONCE(sysctl_wmem_default);\t//即使是udp也设置状态为TCP_CLOSE\tsk-&gt;sk_state\t\t=\tTCP_CLOSE;\t//好像跟内存分配相关\tsk-&gt;sk_use_task_frag\t=\ttrue;\t//这里关联了sock与socket\tsk_set_socket(sk, sock);\tsock_set_flag(sk, SOCK_ZAPPED);\tif (sock) &#123;\t\t//设置用户配置的type类型给sock\t\tsk-&gt;sk_type\t=\tsock-&gt;type;\t\t//初始化套接字的等待队列\t\tRCU_INIT_POINTER(sk-&gt;sk_wq, &amp;sock-&gt;wq);\t\tsock-&gt;sk\t=\tsk;\t&#125; else &#123;\t\tRCU_INIT_POINTER(sk-&gt;sk_wq, NULL);\t&#125;\t//设置sock的uid\tsk-&gt;sk_uid\t=\tuid;\t\t//锁相关，没看太懂\trwlock_init(&amp;sk-&gt;sk_callback_lock);\tif (sk-&gt;sk_kern_sock)\t\tlockdep_set_class_and_name(\t\t\t&amp;sk-&gt;sk_callback_lock,\t\t\taf_kern_callback_keys + sk-&gt;sk_family,\t\t\taf_family_kern_clock_key_strings[sk-&gt;sk_family]);\telse\t\tlockdep_set_class_and_name(\t\t\t&amp;sk-&gt;sk_callback_lock,\t\t\taf_callback_keys + sk-&gt;sk_family,\t\t\taf_family_clock_key_strings[sk-&gt;sk_family]);\tsk-&gt;sk_state_change\t=\tsock_def_wakeup; //唤醒睡眠的进程，比如tcp状态发生改变的时候调用\tsk-&gt;sk_data_ready\t=\tsock_def_readable; //软中断收到数据包，唤醒睡眠的进程\tsk-&gt;sk_write_space\t=\tsock_def_write_space;//有写的空间，唤醒,好像几乎不会被调用\tsk-&gt;sk_error_report\t=\tsock_def_error_report;\tsk-&gt;sk_destruct\t\t=\tsock_def_destruct; //销毁套接字的回调\tsk-&gt;sk_frag.page\t=\tNULL;\tsk-&gt;sk_frag.offset\t=\t0;\tsk-&gt;sk_peek_off\t\t=\t-1;  //peek的偏移量\tsk-&gt;sk_peer_pid \t=\tNULL; //对端的进程id，同一个主机上才有吧？\tsk-&gt;sk_peer_cred\t=\tNULL; //也是对端的信息\tspin_lock_init(&amp;sk-&gt;sk_peer_lock);\tsk-&gt;sk_write_pending\t=\t0;  //写缓存区没有空间了\tsk-&gt;sk_rcvlowat\t\t=\t1;  //唤醒相关的水位线？1表示一个字节也唤醒\tsk-&gt;sk_rcvtimeo\t\t=\tMAX_SCHEDULE_TIMEOUT; //设置接收的超时时间 全F\tsk-&gt;sk_sndtimeo\t\t=\tMAX_SCHEDULE_TIMEOUT; ////设置发送的超时时间 全F\tsk-&gt;sk_stamp = SK_DEFAULT_STAMP;#if BITS_PER_LONG==32\tseqlock_init(&amp;sk-&gt;sk_stamp_seq);#endif\tatomic_set(&amp;sk-&gt;sk_zckey, 0);#ifdef CONFIG_NET_RX_BUSY_POLL\tsk-&gt;sk_napi_id\t\t=\t0;\tsk-&gt;sk_ll_usec\t\t=\tREAD_ONCE(sysctl_net_busy_read);#endif\tsk-&gt;sk_max_pacing_rate = ~0UL;  //发送速率相关，tcp拥塞控制的时候会用到bbr算法会用到\tsk-&gt;sk_pacing_rate = ~0UL;\tWRITE_ONCE(sk-&gt;sk_pacing_shift, 10);\tsk-&gt;sk_incoming_cpu = -1;   //记录属于哪个cpu\tsk_rx_queue_clear(sk);\t/*\t * Before updating sk_refcnt, we must commit prior changes to memory\t * (Documentation/RCU/rculist_nulls.rst for details)\t */\tsmp_wmb();\trefcount_set(&amp;sk-&gt;sk_refcnt, 1);\tatomic_set(&amp;sk-&gt;sk_drops, 0);&#125;EXPORT_SYMBOL(sock_init_data_uid);\n\n上述代码主要做了如下几个个事情，调用sk_init_common 初始化sock的接受队列和发送队列，这个错误队列好像是ip层收到icmp的错误报文，会放到这个错误队列中。\nstatic void sk_init_common(struct sock *sk)&#123;\t//初始化接收，发送和错误队列。\tskb_queue_head_init(&amp;sk-&gt;sk_receive_queue);\tskb_queue_head_init(&amp;sk-&gt;sk_write_queue);\tskb_queue_head_init(&amp;sk-&gt;sk_error_queue);\trwlock_init(&amp;sk-&gt;sk_callback_lock);\t//锁相关没太懂\tlockdep_set_class_and_name(&amp;sk-&gt;sk_receive_queue.lock,\t\t\taf_rlock_keys + sk-&gt;sk_family,\t\t\taf_family_rlock_key_strings[sk-&gt;sk_family]);\tlockdep_set_class_and_name(&amp;sk-&gt;sk_write_queue.lock,\t\t\taf_wlock_keys + sk-&gt;sk_family,\t\t\taf_family_wlock_key_strings[sk-&gt;sk_family]);\tlockdep_set_class_and_name(&amp;sk-&gt;sk_error_queue.lock,\t\t\taf_elock_keys + sk-&gt;sk_family,\t\t\taf_family_elock_key_strings[sk-&gt;sk_family]);\tlockdep_set_class_and_name(&amp;sk-&gt;sk_callback_lock,\t\t\taf_callback_keys + sk-&gt;sk_family,\t\t\taf_family_clock_key_strings[sk-&gt;sk_family]);&#125;\n\n然后在sock_init_data_uid()中初始化了接收缓冲区和发送缓冲区的大小，将socket的sock字段指向当前的sock结构，然后注册唤醒进程睡眠的相关函数，例如收包的唤醒函数，有空间可写的回调函数，tcp状态发生改变的回调函数。\n","categories":["网络协议栈源码学习"],"tags":["socket"]},{"title":"套接字层socket、sock、文件系统之间的关系","url":"/2025/05/21/socket_sock_file_%E6%A6%82%E5%BF%B5/","content":"1.概念内核套接字层（socket layer）是 Linux 网络协议栈中承上启下的一层，负责将用户空间的 socket API（如 socket(), bind(), send(), recv() 等）与内核中的协议栈对接，其核心作用在于实现应用层与传输层协议之间的解耦，为应用程序提供一种统一且抽象的网络通信方式，套接字机制最初由 BSD UNIX 引入，现已广泛应用于各类网络编程环境中。\n套接字层（sockets）在整个网络协议栈中的位置如下图所示：\n\n2.关键数据结构套接字层使用的关键数据结构以及作用如下：\n2.1struct socket作用：是用户空间 socket 文件描述符在内核中的抽象\n核心字段如下所示：\nstruct socket &#123;    socket_state          state;     // 套接字状态    short                 type;      // SOCK_STREAM、SOCK_DGRAM 等    struct sock          *sk;        // 指向内核协议栈的 sock 结构    const struct proto_ops *ops;     // 指向协议操作函数表，如 inet_stream_ops    ...&#125;;\n\n\n\n2.2 struct sock作用：表示一个连接或一个套接字的协议控制块（protocol control block），协议相关逻辑都在这里实现\n核心字段（以 TCP 为例）：\nstruct sock &#123;    struct socket        *sk_socket;    // 回指到 struct socket    struct proto         *sk_prot;      // 协议操作（如 tcp_prot）    struct sk_buff_head   sk_receive_queue; // 接收队列    struct sk_buff_head   sk_write_queue;   // 发送队列    int                   sk_state;     // TCP 状态，如 ESTABLISHED 等    ...&#125;;\n\n2.3 、struct proto_ops作用：socket 操作函数表，对应 socket() 返回的文件描述符上的各种操作，如 send(), recv(), bind()\n核心字段：\nstruct proto_ops &#123;    int (*release)(struct socket *);    int (*bind)(struct socket *, struct sockaddr *, int);    int (*connect)(struct socket *, struct sockaddr *, int, int);    int (*sendmsg)(struct socket *, struct msghdr *, size_t);    int (*recvmsg)(struct socket *, struct msghdr *, size_t, int);    ...&#125;;\n\n2.4  struct proto作用：proto 是 面向传输层抽象设计的接口，把具体协议（TCP、UDP）与上层逻辑解耦，让上层只调用函数指针，而不用管协议细节\nstruct proto &#123;    struct sock *(*alloc)(struct net *, struct socket *, int, gfp_t);    void (*close)(struct sock *sk, long timeout);    int  (*connect)(struct sock *sk, struct sockaddr *uaddr, int addr_len);    int  (*sendmsg)(struct sock *sk, struct msghdr *msg, size_t len);    int  (*recvmsg)(struct sock *sk, struct msghdr *msg, size_t len, int noblock, int flags, int *addr_len);    ...&#125;;\n\n2.5struct file虽不专属于 socket 层，但与 socket 强相关。\n每个 socket 在内核中表现为一个文件，用户空间调用 socket() 后返回的文件描述符 fd 会指向一个 struct file，其 private_data 就是 &#96;struct socket\n2.6 整体关系图下图展示了上述结构体的关系图，其中task_struct对应一个进程，其files指向file_struct结构，该结构的主要功能是管理fd_arry 里面的每个fd对应一个打开的文件，其中的private指针指向的是I&#x2F;O对象的专有数据，对于socket层而言，就是socket结构，socket中的ops可以理解为用户态系统调用的实现。而sock的prot则是根据协议类型，进一步更为具体的实现。\n\n","categories":["网络协议栈源码学习"],"tags":["socket"]},{"title":"网卡硬件各组件","url":"/2025/05/23/%E7%BD%91%E5%8D%A1%E7%A1%AC%E4%BB%B6%E6%A8%A1%E5%9D%97/","content":"网卡核心硬件组成现代有线以太网卡中，MAC、PHY、DMA、PCIe 是网卡最核心的硬件模块，这些模块构成了数据通信的基础框架。以下是它们的详细分工和协作关系，具体的架构图如下所示：\nPHYPHY 层属于 OSI 物理层（Layer 1），主要负责 数字信号 ↔ 模拟信号 的转换，具体包括：\n\n链路管理\n\n\n自动协商​​：与对端设备协商速率（如10&#x2F;100&#x2F;1000 Mbps）和双工模式。\n链路检测​​：监测连接状态（如网线是否插入）。\n\n\n信号转换​\n\n\n数模转换​​：将MAC层生成的数字信号转换为适合线缆（如双绞线、光纤）传输的模拟信号（如电信号或光信号）。\n模数转换​​：将接收到的模拟信号还原为数字信号供上层处理。\n\n\n物理介质适配​\n\n支持不同介质标准（如以太网的RJ-45接口、光纤接口），适应电压、阻抗等物理特性,例如：100BASE-TX（双绞线）、1000BASE-SX（光纤）等。\n\n编码与解码\n\n使用特定编码方案（如曼彻斯特编码、PAM4）以提高抗干扰能力，确保信号完整性。\nMAC\n发送数据时​​，计算 ​​CRC（循环冗余校验）​​，确保数据完整性。\n接收数据时​​：\n从 PHY 层接收原始比特流，解析成以太网帧。\n检查​目标MAC地址​​（仅接收发给本机、广播或组播的帧）。\n校验 ​​FCS​​，丢弃损坏的帧。\n\n\n流量控制：使用 ​​PAUSE 帧（IEEE 802.3x）​​ 通知对端设备暂停发送，防止缓冲区溢出。\n\nDMA数据直接传输，网卡通过DMA引擎直接读写主机内存\nRSSRSS 是一种由 网卡硬件实现 的多队列技术，主要用于 提升多核 CPU 的网络数据包处理性能。网卡硬件将流量分散到多个接收队列（RX Queues），每个队列绑定不同CPU核心。\nTSOTSO 是一种由 网卡硬件实现 的优化技术，旨在 将TCP数据包的分片（Segmentation）任务从CPU转移到网卡，从而大幅降低CPU负载并提升网络吞吐量。\nPCIe\n提供网卡与CPU&#x2F;内存的物理通道，决定最大带宽（如100G需PCIe 4.0 x8）。\n支持DMA、MSI-X中断，优化响应速度\n\n","categories":["其他"],"tags":["网卡"]},{"title":"socket文件系统","url":"/2025/05/26/socket%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/","content":"1.套接字与文件系统每一种文件都有各自的文件类型，例如设备文件包括字符设备文件和块设备文件等，而与套接字关联的文件类型为套接字文件。\n1.1套接字文件系统的注册为了能够让套接字与文件描述符相关联，并支持特殊套接字曾的节点分配和释放，系统中增加了sockfs文件系统类型sock_fs_type,具体定义如下：\nstatic struct file_system_type sock_fs_type = &#123;\t.name =\t\t&quot;sockfs&quot;, //文件系统名字\t//挂载的时候会被调用，在kern_mount()被调用\t.init_fs_context = sockfs_init_fs_context,//初始化文件系统的回调函数，\t.kill_sb =\tkill_anon_super,//卸载文件系统&#125;;\nsock_fs_type类型的文件系统注册发生在sock_init()在start_kernel中经过一些列调用会被调到.\n//start_kernel会调用到它static int __init sock_init(void)&#123;    ...\t//注册socket类型的文件系统\terr = register_filesystem(&amp;sock_fs_type);\tif (err)\t\tgoto out;    //挂载这个文件系统，返回一个超级块\tsock_mnt = kern_mount(&amp;sock_fs_type);\tif (IS_ERR(sock_mnt)) &#123;\t\terr = PTR_ERR(sock_mnt);\t\tgoto out_mount;\t&#125;    ....&#125;\n\n在上述代码中首先调用register_filesystem(&amp;sock_fs_type);来注册socket文件系统，主要工作判断是否有相同名字文件系统并插入到链表中。然后调用kern_mount完成挂载操作并返回一个超级块，在创建socket的时候创建inode就是用的这个超级块的alloc_node回调函数。kern_mount函数定义如下\nstruct vfsmount *kern_mount(struct file_system_type *type)&#123;\tstruct vfsmount *mnt;\t//实际的挂载操作\tmnt = vfs_kern_mount(type, SB_KERNMOUNT, type-&gt;name, NULL);\tif (!IS_ERR(mnt)) &#123;\t\t/*\t\t * it is a longterm mount, don&#x27;t release mnt until\t\t * we unmount before file sys is unregistered\t\t*/\t\treal_mount(mnt)-&gt;mnt_ns = MNT_NS_INTERNAL;\t&#125;\treturn mnt;&#125;\n\n上述代码调用vfs_kern_mount中调用了vfs_kern_mount完成实际的挂载，返回的为一个挂载点，其中SB_KERNMOUNT表示表示该挂载属于内核内部命名空间。\n在vfs_kern_mount中的工作就是创建一个fs_context结构体，把具体文件系统的回调函数与ctx-&gt;ops相关联，，这里的ctx是fs的一个私有结构。然后通过fc_mount中的get_tree把sb与ctx-&gt;ops关联了起来\nstruct vfsmount *vfs_kern_mount(struct file_system_type *type,\t\t\t\tint flags, const char *name,\t\t\t\tvoid *data)&#123;\tstruct fs_context *fc;\t//mnt为返回的挂载点\tstruct vfsmount *mnt;\tint ret = 0;\tif (!type)\t\treturn ERR_PTR(-EINVAL);\t\t//分配一个fs结构，并初始化，这里把具体文件系统的回调函数与ctx-&gt;ops相关联\t//fs为ctx的一个私有结构\tfc = fs_context_for_mount(type, flags);\tif (IS_ERR(fc))\t\treturn ERR_CAST(fc);\tif (name)\t\tret = vfs_parse_fs_string(fc, &quot;source&quot;,\t\t\t\t\t  name, strlen(name));\tif (!ret)\t\tret = parse_monolithic_mount_data(fc, data);\tif (!ret)\t//分配并初始化超级块和挂载点\t//注意这里面的get_tree把超级块与ctx-&gt;ops关联了起来\t\tmnt = fc_mount(fc);\telse\t\tmnt = ERR_PTR(ret);\tput_fs_context(fc);\treturn mnt;&#125;\nfs_context_for_mount是一个包裹函数，最终实际调用的是alloc_fs_context 核心逻辑就是创建一个fs结构体并初始化然后调用文件系统注册的init_fs_context函数，将fs的ctx与文件系统的ops关联上。 函数原型如下：\nstatic struct fs_context *alloc_fs_context(struct file_system_type *fs_type,\t\t\t\t      struct dentry *reference,\t\t\t\t      unsigned int sb_flags,\t\t\t\t      unsigned int sb_flags_mask,\t\t\t\t      enum fs_context_purpose purpose)&#123;\tint (*init_fs_context)(struct fs_context *);\tstruct fs_context *fc;\tint ret = -ENOMEM;\t//分配一个fc\tfc = kzalloc(sizeof(struct fs_context), GFP_KERNEL_ACCOUNT);\tif (!fc)\t\treturn ERR_PTR(-ENOMEM);\tfc-&gt;purpose\t= purpose;\tfc-&gt;sb_flags\t= sb_flags;\tfc-&gt;sb_flags_mask = sb_flags_mask;\tfc-&gt;fs_type\t= get_filesystem(fs_type);\tfc-&gt;cred\t= get_current_cred();\tfc-&gt;net_ns\t= get_net(current-&gt;nsproxy-&gt;net_ns);\tfc-&gt;log.prefix\t= fs_type-&gt;name;\tmutex_init(&amp;fc-&gt;uapi_mutex);\tswitch (purpose) &#123;\tcase FS_CONTEXT_FOR_MOUNT:\t\tfc-&gt;user_ns = get_user_ns(fc-&gt;cred-&gt;user_ns);\t\tbreak;\tcase FS_CONTEXT_FOR_SUBMOUNT:\t\tfc-&gt;user_ns = get_user_ns(reference-&gt;d_sb-&gt;s_user_ns);\t\tbreak;\tcase FS_CONTEXT_FOR_RECONFIGURE:\t\tatomic_inc(&amp;reference-&gt;d_sb-&gt;s_active);\t\tfc-&gt;user_ns = get_user_ns(reference-&gt;d_sb-&gt;s_user_ns);\t\tfc-&gt;root = dget(reference);\t\tbreak;\t&#125;\t/* TODO: Make all filesystems support this unconditionally */\tinit_fs_context = fc-&gt;fs_type-&gt;init_fs_context;\tif (!init_fs_context)\t\tinit_fs_context = legacy_init_fs_context;\t//调用文件系统的init函数，将fs与文件系统的ops关联上。\tret = init_fs_context(fc);\tif (ret &lt; 0)\t\tgoto err_fc;\tfc-&gt;need_free = true;\treturn fc;err_fc:\tput_fs_context(fc);\treturn ERR_PTR(ret);&#125;\nret = init_fs_context(fc); 为上述文件系统注册的回调函数\nstatic int sockfs_init_fs_context(struct fs_context *fc)&#123;\tstruct pseudo_fs_context *ctx = init_pseudo(fc, SOCKFS_MAGIC);\tif (!ctx)\t\treturn -ENOMEM;\tctx-&gt;ops = &amp;sockfs_ops;//alloc_inode ,free_inode\tctx-&gt;dops = &amp;sockfs_dentry_operations;\tctx-&gt;xattr = sockfs_xattr_handlers;\treturn 0;&#125;\n\n上述init_pseudo()中主要zu了两件事，申请了ctx结构作为fs的私有结构，然后注册了get_tree回调函数。这个get_tree ，回调里面的逻辑就是创建一个超级块，然后将ctx的ops赋值给超级块的ops，在fc_mount中会调用这个回调函数，函数定义如下所示：\nstatic const struct fs_context_operations pseudo_fs_context_ops = &#123;\t.free\t\t= pseudo_fs_free,\t.get_tree\t= pseudo_fs_get_tree,//创建了一个超级块最终会调用err = fill_super(sb, fc);填充超级块&#125;;struct pseudo_fs_context *init_pseudo(struct fs_context *fc,\t\t\t\t\tunsigned long magic)&#123;\tstruct pseudo_fs_context *ctx;\tctx = kzalloc(sizeof(struct pseudo_fs_context), GFP_KERNEL);\tif (likely(ctx)) &#123;\t\tctx-&gt;magic = magic;\t\tfc-&gt;fs_private = ctx;//设置私有结构\t\tfc-&gt;ops = &amp;pseudo_fs_context_ops; //设置ops集合，如上述代码所示\t\tfc-&gt;sb_flags |= SB_NOUSER;\t\tfc-&gt;global = true;\t&#125;\treturn ctx;&#125;\n\n上述fs_context_for_mount函数在vfs_kern_mount中被调用后会调用fc_mount来申请一个超级块，并初始化相关字段\nstruct vfsmount *fc_mount(struct fs_context *fc)&#123;\t//创建并初始化超级块\tint err = vfs_get_tree(fc);\tif (!err) &#123;\t\tup_write(&amp;fc-&gt;root-&gt;d_sb-&gt;s_umount);\t\t//创建挂载点\t\treturn vfs_create_mount(fc);\t&#125;\treturn ERR_PTR(err);&#125;\nvfs_get_tree中调用fc-&gt;ops-&gt;get_tree(fc)创建并初始化了超级块，代码如下所示：\nint vfs_get_tree(struct fs_context *fc)&#123;\tstruct super_block *sb;\tint error;\tif (fc-&gt;root)\t\treturn -EBUSY;\t//这里创建了超级块\terror = fc-&gt;ops-&gt;get_tree(fc);\tif (error &lt; 0)\t\treturn error;\tif (!fc-&gt;root) &#123;\t\tpr_err(&quot;Filesystem %s get_tree() didn&#x27;t set fc-&gt;root\\n&quot;,\t\t       fc-&gt;fs_type-&gt;name);\t\t/* We don&#x27;t know what the locking state of the superblock is -\t\t * if there is a superblock.\t\t */\t\tBUG();\t&#125;\t//将申请的sb赋值给sb\tsb = fc-&gt;root-&gt;d_sb;\tWARN_ON(!sb-&gt;s_bdi);\tsuper_wake(sb, SB_BORN);\terror = security_sb_set_mnt_opts(sb, fc-&gt;security, 0, NULL);\tif (unlikely(error)) &#123;\t\tfc_drop_locked(fc);\t\treturn error;\t&#125;\tWARN((sb-&gt;s_maxbytes &lt; 0), &quot;%s set sb-&gt;s_maxbytes to &quot;\t\t&quot;negative value (%lld)\\n&quot;, fc-&gt;fs_type-&gt;name, sb-&gt;s_maxbytes);\treturn 0;&#125;","categories":["网络协议栈源码学习"],"tags":["socket","VFS"]},{"title":"x86汇编学习(一)","url":"/2025/05/27/x86%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89/","content":"汇编语言GCC（C语言编译器）可以将程序编译为汇编代码的形式进行输出。汇编语言是机器指令的文本表示形式，它详细地列出了程序中每一条指令。然后GCC 会调用汇编器（assembler）和链接器（linker），根据这些汇编代码生成最终的可执行机器代码。\n本文基于x86-64架构,\t 它是现在最常见处理器的机器语言，也是驱动大型数据中心和超级计算机的最常见处理器的机器语言。这种语言的历史悠久，开始 于 Intel 公司 1978 年的第一个 16 位处理器，然后扩展为 32 位，最近又扩展到 64 位。\n1.x86的发展过程8086(1978 年， 29K 个晶体管）。它是第一代单芯片、 16 位微处理器之一。 \ni386(1985 年， 275K 个晶体管）。将体系结构扩展到 32 位。这是 Intel 系列中第一台全面支持 Unix操作系统的机器。\nPentium 4E(2004 年， 125M 个品体管）。增加了超线程(hyperthreading) , 这种技术可以在一个处理器上同时运行两个程序；还增加了 EM64T, 它是 Intel 对AMD提出的对 IA32 的 64 位扩展的实现，我们称之为 x86-64。\n2.程序编码假设一个C程序，有两个文件p1.c 和 p2.c 我们用 Unix命令行编译这些代码：\nlinux&gt; gcc -Og -o p p1.c p2.c \n\n命令 gcc 指的就是 GCC C 编译器。因为这是 Linux上默认的编译器。编译选项-Og告诉编译器使用的优化等级。\n实际上 gcc 命令调用了一整套的程序，将源代码转化成可执行代码。首先， C预处理器扩展源代码，插入所有用#include命令指定的文件，并展开所有用#define 声明指定的宏。其次，编译器产生两个源文件的汇编代码，名字分别为 p1.s 和 p2.s。接下来，汇编器会将汇编代码转化成二进制目标代码文件p1.a 和 p2.o。 目标代码是机器代码的一种形式，它包含所有指令的二进制表示，但是还没有填入全局值的地址（此时全局变量的地址应该没有确定）。最后，链接器将两个目标代码文件与实现库函数（例如printf)的代码合并，并产生最终的可执行代码文件p。\n虽然 C语言提供了一种模型，可以在内存中声明和分配各种数据类型的对象**，但是机器码只是简单地将内存看成一个很大的、按字节寻址的数组**。 C语言中的数据类型，例如数组和结构体，在机器代码中用一组连续的字节来表示。\n代码示例：\n假设我们写了一个 C 语言代码文件 mstore.c，包含如下的函数定义：\nlong mult2(long, long);void multstore(long x, long y, long *dest) &#123;    long t = mult2(x, y);    *dest = t;&#125;\n\n在命令行上使用 -S 选项，就能看到 C 语言编译器产生的汇编代码\nlinux&gt; gcc -Og -S mstore.c\n\n这会使 GCC 运行编译器，产生一个汇编文件 mstore.s，但是不做其他进一步的工作。（通常情况下，它还会继续调用汇编器产生目标代码文件）。\n汇编代码文件包含各种声明，包括下面几行：\nmultstore:    pushq   %rbx //把寄存器 %rbx 的值压栈，保存现场，防止被后面修改    movq    %rdx, %rbx //把第三个参数（dest 指针）保存到 %rbx 中，因为调用 mult2 之后 %rdx 可能会被破坏    call    mult2 //调用 mult2(x, y) 函数（参数 x 和 y 存在 %rdi 和 %rsi 中）。    movq    %rax, (%rbx) //将 mult2 的返回值（在 %rax 中）存储到 %rbx 指向的地址中，也就是 *dest = result。    popq    %rbx //恢复之前保存的 %rbx 的值，保持寄存器一致性。    ret\n\n要查看机器代码文件的内容，有一类称为反汇编器（disassembler）的程序非常有用。这些程序根据机器代码产生一种类似于汇编代码的格式。在 Linux 系统中，带 -d 命令行标志的程序 objdump（表示 “object dump”）可以充当这个角色：\nlinux&gt; objdump -d mstore.o\n\n结果如下\nDisassembly of function multstore in binary file mstore.o0000000000000000 &lt;multstore&gt;: Offset  Bytes         Equivalent assembly language----------------------------------------------------  0:     53            push   %rbx                ; 保存 %rbx 到栈中  1:     48 89 d3      mov    %rdx, %rbx          ; 把第三个参数 dest 存入 %rbx  4:     e8 00 00 00 00 callq  9 &lt;multstore+0x9&gt;  ; 调用 mult2(x, y)  9:     48 89 03      mov    %rax, (%rbx)        ; 把结果保存到 *dest 中  c:     5b            pop    %rbx                ; 恢复 %rbx  d:     c3            retq                       ; 返回\n\n\n\n然而生成实际可执行的代码需要对一组目标代码文件运行链接器，而这一组目标代码文件中必须含有一个main 函数。假设在文件 main.c 中有下面这样的函数：\n#include &lt;stdio.h&gt;void multstore(long, long, long *);int main() &#123;    long d;    multstore(2, 3, &amp;d);    printf(&quot;2 * 3 --&gt; %ld\\n&quot;, d);    return 0;&#125;long mult2(long a, long b) &#123;    long s = a * b;    return s;&#125;\n\n用如下命令成可执行文件prog:\nlinux&gt; gcc -Og -o prog main.c mstore.c\n\n我们也可以反汇编 prog 文件\nDisassembly of function sum multstore binary file prog0000000000400540 &lt;multstore&gt;: Offset     Bytes             Equivalent assembly language---------------------------------------------------------- 400540:    53                push   %rbx 400541:    48 89 d3          mov    %rdx, %rbx 400544:    e8 42 00 00 00    callq  40058b &lt;mult2&gt; 400549:    48 89 03          mov    %rax, (%rbx) 40054c:    5b                pop    %rbx 40054d:    c3                retq 40054e:    90                nop 40054f:    90                nop\n\n这段代码与 mstore.c 反汇编产生的代码几乎完全一样。其中一个主要的区别是左边列出的地址不同——链接器将这段代码的地址移动到了一段不同的地址范围中。第二个不同之处在于链接器填上了 callq 指令调用函数 mult2 需要使用的地址（反汇编代码第 4 行）。链接器的任务之一就是为函数调用匹配到可执行代码中函数的地址.（这里的地址0000000000400540应该就是虚拟内存中的地址）\n3.汇编伪指令假设我们用如下命令生成文件 mstore.s完整的汇编文件代码如下所示：\n\t.file\t&quot;010-mstore.c&quot; //告诉汇编器这个文件来源于哪个源文件（调试信息用）\t.text  \t\t\t\t\t//告诉汇编器后面的内容是程序代码\t.globl\tmultstore \t\t//使函数对其他文件可见（链接时可调用）\t.type\tmultstore, @function //\t指定符号类型是函数\t供链接器识别该符号为函数multstore:\tpushq\t%rbx\tmovq\t%rdx, %rbx\tcall\tmult2\tmovq\t%rax, (%rbx)\tpopq\t%rbx\tret\t.size\tmultstore, .-multstore //告诉链接器这个函数占用了多少字节。在 ELF 格式中，每个符号都可以带有大小信息\t.ident\t&quot;GCC: (Ubuntu 4.8.1-2ubuntu1~12.04) 4.8.1&quot; //加入一条标识信息，说明是用什么编译器编译的。\t.section\t.note.GNU-stack,&quot;&quot;,@progbits\n\n所有以 . 开头的行都是指导汇编器和链接器工作的伪指令。\n4.C 类型与汇编指令后缀对应表 Intel 用术语”字(word)” 表示 16 位数据类型。因此，称 32 位数为“双字”, 称 64 位数为“四字” 下表为C语言基本数据类型对应的 x86-64 表示：\n\n\n\nC 声明\nIntel 数据类型\n汇编代码后缀\n大小（字节）\n\n\n\nchar\n字节\nb（byte）\n1 字节\n\n\nshort\n字\nw（word）\n2 字节\n\n\nint\n双字\nl（long）\n4 字节\n\n\nlong\n四字\nq（quad）\n8 字节\n\n\nchar*\n四字（指针）\nq\n8 字节\n\n\nfloat\n单精度\ns（single）\n4 字节\n\n\ndouble\n双精度\nl（long）\n8 字节\n\n\n 汇编后缀的意义：\n在 x86-64 汇编中，许多指令都有后缀来说明操作数的数据大小：\n\nmovb：移动 1 字节（byte）\nmovw：移动 2 字节（word）\nmovl：移动 4 字节（long word）\nmovq：移动 8 字节（quad word）\n\n5.x86-64 架构下的通用寄存器通用寄存器：临时存储运算数据、函数参数、返回值、地址、计数、内存地址等各种信息，能够加快数据处理速度，减少内存读写等\n每个寄存器的用途（按调用约定）如下表所示：\n\n\n\n64位寄存器\n32位\n16位\n8位\n用途说明\n\n\n\n%rax\n%eax\n%ax\n%al\n返回值寄存器\n\n\n%rbx\n%ebx\n%bx\n%bl\n被调用者保存\n\n\n%rcx\n%ecx\n%cx\n%cl\n第4个参数\n\n\n%rdx\n%edx\n%dx\n%dl\n第3个参数\n\n\n%rsi\n%esi\n%si\n%sil\n第2个参数\n\n\n%rdi\n%edi\n%di\n%dil\n第1个参数\n\n\n%rbp\n%ebp\n%bp\n%bpl\n被调用者保存\n\n\n%rsp\n%esp\n%sp\n%spl\n栈指针\n\n\n%r8\n%r8d\n%r8w\n%r8b\n第5个参数\n\n\n%r9\n%r9d\n%r9w\n%r9b\n第6个参数\n\n\n%r10\n%r10d\n%r10w\n%r10b\n调用者保存\n\n\n%r11\n%r11d\n%r11w\n%r11b\n调用者保存\n\n\n%r12\n%r12d\n%r12w\n%r12b\n被调用者保存\n\n\n%r13\n%r13d\n%r13w\n%r13b\n被调用者保存\n\n\n%r14\n%r14d\n%r14w\n%r14b\n被调用者保存\n\n\n%r15\n%r15d\n%r15w\n%r15b\n被调用者保存\n\n\n所有这些寄存器本质上都是 64 位的，但我们可以只访问其中的低 32、16、8 位（如上表第二，第三，第四列所示）\n与专用寄存器的区别：\n\n\n\n类型\n说明\n例子\n\n\n\n通用寄存器\n用于各种灵活数据操作\n%rax, %rdi\n\n\n专用寄存器\n有固定用途\n%rip（指令指针），%cr3（控制）\n\n\n段寄存器\n用于段地址（早期保护模式）\n%cs, %ds\n\n\n标志寄存器\n保存运算结果标志\n%eflags\n\n\n6.x86 汇编寻址方式表寻址（Addressing）就是确定数据所在地址的过程，具体汇编的格式和含义如下表所示：\n\n\n\n类型\n格式\n操作数值表示\n名称（寻址方式）\n\n\n\n立即数\n$Imm\nImm\n立即数寻址（Immediate Addressing）\n\n\n寄存器\nr_a\nR[r_a]\n寄存器寻址（Register Addressing）\n\n\n存储器\nImm\nM[Imm]\n绝对寻址（Absolute Addressing）\n\n\n存储器\n(r_a)\nM[R[r_a]]\n间接寻址（Indirect Addressing）\n\n\n存储器\nImm(r_b)\nM[Imm + R[r_b]]\n基址 + 偏移量（Base + Offset）寻址\n\n\n存储器\n(r_b, r_i)\nM[R[r_b] + R[r_i]]\n变址寻址（Indexed Addressing）\n\n\n存储器\nImm(r_b, r_i)\nM[Imm + R[r_b] + R[r_i]]\n变址 + 偏移量寻址\n\n\n存储器\n(r_i, s)\nM[R[r_i] * s]\n比例变址寻址（Scaled Index）\n\n\n存储器\nImm(,r_i,s)\nM[Imm + R[r_i] * s]\n比例变址 + 偏移量寻址\n\n\n存储器\n(r_b, r_i, s)\nM[R[r_b] + R[r_i] * s]\n比例变址 + 基址寻址\n\n\n存储器\nImm(r_b, r_i, s)\nM[Imm + R[r_b] + R[r_i] * s]\n比例变址 + 基址 + 偏移量寻址\n\n\n格式指的是在汇编语言中书写一个操作数（比如常量、寄存器或内存地址）时，它的语法结构长什么样，也就是“写法”。\n操作数表示是指汇编语言中那个操作数在执行时真正的数值含义，如下表所示：\n\n\n\n概念\n意义\n举例\n\n\n\n格式\n汇编里写法\n8(%rbp)\n\n\n操作数表示\n真正要访问的值的含义\nM[8 + R[rbp]]\n\n\n举例：\n\n立即数寻址（Immediate Addressing）\n\nmov $5, %eax      # 把常量 5 移到寄存器 eax 中\n\n\n寄存器寻址（Register Addressing）\n\nmov %ebx, %eax    # 把 %ebx 里的值复制到 %eax\n\n\n间接寻址（Indirect Addressing)\n\nmov (%rbx), %eax  # 把 %rbx 指向的内存地址中的值加载到 %eax\n\n\n基址 + 偏移寻址（Base + Offset)\n\nmov 8(%rbp), %eax # 取栈帧中偏移 8 字节的变量到 %eax\n\n","categories":["《深入理解计算机系统》"],"tags":["汇编语言"]},{"title":"socket与文件描述符的映射","url":"/2025/05/27/socket%E4%B8%8E%E6%96%87%E4%BB%B6%E6%8F%8F%E8%BF%B0%E7%AC%A6%E7%9A%84%E6%98%A0%E5%B0%84/","content":"socket与文件描述符的映射1.socket与fd的映射应用层是通过文件描述符来找到内核的socket的一系列结构，因此在调用socket系统调用创建socket的过程中，会将一个fd与一个套接字相关联，对应的函数为__sys_socket函数中的sock_map_fd在sock_map_fd中，主要做了如下几个事情，获取一个空闲的文件描述符，创建一个file实例，将fd与file实例绑定，然后将这个file实例加入到进程打开的文件指针数组中，然后再将套接字与file相关连。这样fd，file，进程，socket四者之间就紧密的联系在了一起。代码如下：\nstatic int sock_map_fd(struct socket *sock, int flags)&#123;\tstruct file *newfile;\t//从当前进程获取一个未使用的文件描述符fd\tint fd = get_unused_fd_flags(flags);\tif (unlikely(fd &lt; 0)) &#123;\t\tsock_release(sock);\t\treturn fd;\t&#125;\t//创建一个文件对象\tnewfile = sock_alloc_file(sock, flags, NULL);\t//关联fd和文件对象\tif (!IS_ERR(newfile)) &#123;\t\tfd_install(fd, newfile);\t\treturn fd;\t&#125;\t//有错误，将fd标记为未使用\tput_unused_fd(fd);\treturn PTR_ERR(newfile);&#125;\n\n上述代码调用get_unused_fd_flags是一个包裹函数最终调用return alloc_fd(0, nofile, flags);获取一个未使用的文件描述符。\nstatic int alloc_fd(unsigned start, unsigned end, unsigned flags)&#123;\t//获取当前进程的文件描述副列表\tstruct files_struct *files = current-&gt;files;\tunsigned int fd;\tint error;\t//fd表，用来指向files_struct的fdtable\tstruct fdtable *fdt;\tspin_lock(&amp;files-&gt;file_lock);repeat:\t//这里指了一下\tfdt = files_fdtable(files);\tfd = start;\t//跳过已分配的fd\tif (fd &lt; files-&gt;next_fd)\t\tfd = files-&gt;next_fd;\tif (fd &lt; fdt-&gt;max_fds)\t//返回一个没有被使用的fd\t\tfd = find_next_fd(fdt, fd);\t/*\t * N.B. For clone tasks sharing a files structure, this test\t * will limit the total number of files that can be opened.\t */\terror = -EMFILE;\tif (fd &gt;= end)\t\tgoto out;\t//这里面会判断当前的fd是否大于max_fd,如果大于可能需要对​​文件描述符表的扩容\terror = expand_files(files, fd);\tif (error &lt; 0)\t\tgoto out;\t/*\t * If we needed to expand the fs array we\t * might have blocked - try again.\t */\t//可能会阻塞在试一次\tif (error)\t\tgoto repeat;\t//这里修改一下下一个要分配的fd，加速一下\tif (start &lt;= files-&gt;next_fd)\t\tfiles-&gt;next_fd = fd + 1;\t//设置已经使用的标志\t__set_open_fd(fd, fdt);\tif (flags &amp; O_CLOEXEC)\t\t__set_close_on_exec(fd, fdt);\telse\t\t__clear_close_on_exec(fd, fdt);\terror = fd;#if 1\t/* Sanity check */\tif (rcu_access_pointer(fdt-&gt;fd[fd]) != NULL) &#123;\t\tprintk(KERN_WARNING &quot;alloc_fd: slot %d not NULL!\\n&quot;, fd);\t\trcu_assign_pointer(fdt-&gt;fd[fd], NULL);\t&#125;#endifout:\tspin_unlock(&amp;files-&gt;file_lock);\treturn error;&#125;\n\n上述代码参数中的start为0,end为系统配置一个进程最多持有的描述数量，默认通常是1024，最大是多少？？如果文件描述副的fd大于了end则会报错打开了太多文件描述符。申请到fd之后在sock_map_fd中会调用sock_alloc_file创建文件对象，具体代码如下：\nstruct file *sock_alloc_file(struct socket *sock, int flags, const char *dname)&#123;\tstruct file *file;\tif (!dname)\t\tdname = sock-&gt;sk ? sock-&gt;sk-&gt;sk_prot_creator-&gt;name : &quot;&quot;;\t//alloc一个file绑定了socket_file_ops 回调函数集合 sock_mnt为一个挂在点\tfile = alloc_file_pseudo(SOCK_INODE(sock), sock_mnt, dname,\t\t\t\tO_RDWR | (flags &amp; O_NONBLOCK),\t\t\t\t&amp;socket_file_ops);\tif (IS_ERR(file)) &#123;\t\tsock_release(sock);\t\treturn file;\t&#125;\tfile-&gt;f_mode |= FMODE_NOWAIT;\tsock-&gt;file = file;\t//注意：这里关联了socket和file\tfile-&gt;private_data = sock;\t//标记为流式文件，不支持lseek(随机访问)？\tstream_open(SOCK_INODE(sock), file);\treturn file;&#125;\n\n上述sock_alloc_file中调用alloc_file_pseudo创建了一个file结构和dentry结构，并把sock对应的inode和denry相关联，然后在alloc_file_pseudo中将file的私有指针指向socket。这一系列逻辑完成了file，socket，inode，dentry，之间的关联和绑定了文件的ops，之后就可以通过file可以找到socket，通过dentry可以快速找到inode通过inode也可以找到socket。alloc_file_pseudo实现如下:\nstruct file *alloc_file_pseudo(struct inode *inode, struct vfsmount *mnt,\t\t\t\tconst char *name, int flags,\t\t\t\tconst struct file_operations *fops)&#123;\tstatic const struct dentry_operations anon_ops = &#123;\t\t.d_dname = simple_dname\t&#125;;\tstruct qstr this = QSTR_INIT(name, strlen(name));\tstruct path path;\tstruct file *file;\t//创建一个dentry\tpath.dentry = d_alloc_pseudo(mnt-&gt;mnt_sb, &amp;this);\tif (!path.dentry)\t\treturn ERR_PTR(-ENOMEM);\tif (!mnt-&gt;mnt_sb-&gt;s_d_op)\t\td_set_d_op(path.dentry, &amp;anon_ops);\t//给挂载点加一个引用计数\tpath.mnt = mntget(mnt);\t//关联denry和socket的inode 之后可以通过这个dentry快速找到inode\td_instantiate(path.dentry, inode);\t//申请一个file，同时挂上ops (也就是read，write)\tfile = alloc_file(&amp;path, flags, fops);\tif (IS_ERR(file)) &#123;\t\tihold(inode);\t\tpath_put(&amp;path);\t&#125;\treturn file;&#125;\n\n当申请了fd和file结构之后，会调用fd_install 完成文件描述fd与file的关联，此后用户就可以通过这个fd找到file，通过file找到socket，等等一系列信息。\nvoid fd_install(unsigned int fd, struct file *file)&#123;\tstruct files_struct *files = current-&gt;files;\tstruct fdtable *fdt;\trcu_read_lock_sched();\tif (unlikely(files-&gt;resize_in_progress)) &#123;\t\trcu_read_unlock_sched();\t\tspin_lock(&amp;files-&gt;file_lock);\t\tfdt = files_fdtable(files);\t\tBUG_ON(fdt-&gt;fd[fd] != NULL);\t\t//将fdt表的fd元素指向外面申请的file，这个file的私有结构就是socket！\t\trcu_assign_pointer(fdt-&gt;fd[fd], file);\t\tspin_unlock(&amp;files-&gt;file_lock);\t\treturn;\t&#125;\t/* coupled with smp_wmb() in expand_fdtable() */\tsmp_rmb();\tfdt = rcu_dereference_sched(files-&gt;fdt);\tBUG_ON(fdt-&gt;fd[fd] != NULL);\trcu_assign_pointer(fdt-&gt;fd[fd], file);\trcu_read_unlock_sched();&#125;\n\n2.根据文件描述符获取套接字当用户创建socket返回fd之后，执行bind，listen，send，recv都要传入上述提到的fd，内核会根据用户传入的fd找到对应的文件file，进而通过私有指针找到socket，对应的函数接口为sockfd_lookup_light\n//返回值为socketstatic struct socket *sockfd_lookup_light(int fd, int *err, int *fput_needed)&#123;\t\t//根据fd从进程管理的fdtable中找到对应的file，这里struct fd结构体中的一个字段为file\tstruct fd f = fdget(fd);\tstruct socket *sock;\t*err = -EBADF;\tif (f.file) &#123;\t\t//从file的私有指针中拿到socket\t\tsock = sock_from_file(f.file);\t\tif (likely(sock)) &#123;\t\t\t*fput_needed = f.flags &amp; FDPUT_FPUT;\t\t\treturn sock;\t\t&#125;\t\t*err = -ENOTSOCK;\t\tfdput(f);\t&#125;\treturn NULL;&#125;\n\n上述fdget最终调用到__fget_light，具体代码如下：\nstatic unsigned long __fget_light(unsigned int fd, fmode_t mask)&#123;\t//通过current宏获取文件描述符表\tstruct files_struct *files = current-&gt;files;\tstruct file *file;\t/*\t * If another thread is concurrently calling close_fd() followed\t * by put_files_struct(), we must not observe the old table\t * entry combined with the new refcount - otherwise we could\t * return a file that is concurrently being freed.\t *\t * atomic_read_acquire() pairs with atomic_dec_and_test() in\t * put_files_struct().\t */\t//判断当前进程的文件描述符表是否被其他进程共享，如果没有被共享，直接无锁查找\tif (atomic_read_acquire(&amp;files-&gt;count) == 1) &#123;\t\t//逻辑很简单，直接根据fd取对应的files\t\tfile = files_lookup_fd_raw(files, fd);\t\tif (!file || unlikely(file-&gt;f_mode &amp; mask))\t\t\treturn 0;\t\treturn (unsigned long)file;\t&#125; else &#123;\t\t//加rcu锁查找，多线程可能会走这里吧？？？\t\tfile = __fget(fd, mask);\t\tif (!file)\t\t\treturn 0;\t\treturn FDPUT_FPUT | (unsigned long)file;\t&#125;&#125;\n\n上述查找file的过程可以分为快速路径和慢速路径，当文件描述符表存在被多个线程访问时，需要加锁访问，否则直接走快速路径无锁拿到file(atomic_read_acquire(&amp;files-&gt;count))\n","categories":["网络协议栈源码学习"],"tags":["socket"]}]